{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess all the training data.\n",
    "Builds a vocabulary and converts all sentences into numerical indices\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = os.environ.get(\"P4_DATA_ROOT\", \"data/\")\n",
    "\n",
    "\n",
    "def read_labeled_sentences(f):\n",
    "    out = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        label, sent = line.split(\"\\t\")\n",
    "        words = sent.split()\n",
    "        bool_label = label == 'POS'\n",
    "        out.append((bool_label, words))\n",
    "    return out\n",
    "\n",
    "\n",
    "def read_unlabeled_sentences(f):\n",
    "    out = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        words = line.split()\n",
    "        out.append(words)\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"train.txt\")) as f:\n",
    "        train_sents = read_labeled_sentences(f)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"valid.txt\")) as f:\n",
    "        valid_sents = read_labeled_sentences(f)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"test.txt\")) as f:\n",
    "        test_sents = read_labeled_sentences(f)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"unlabeled.txt\")) as f:\n",
    "        unlabeled_sents = read_unlabeled_sentences(f)\n",
    "\n",
    "\n",
    "    # establish the vocabulary\n",
    "    ##########################\n",
    "\n",
    "    # start with list of most common words, labeled or unlabeled\n",
    "    word_counter = Counter(w for _, sent in train_sents for w in sent)\n",
    "    word_counter.update(w for sent in unlabeled_sents for w in sent)\n",
    "\n",
    "    # toss words that don't appear at least 10 times\n",
    "    vocab = [w for w, _ in word_counter.most_common()\n",
    "             if word_counter[w] >= 10]\n",
    "\n",
    "    # add special tokens\n",
    "    unk = '__UNK__'\n",
    "    s_start = '__START__'\n",
    "    s_end = '__END__'\n",
    "    vocab = [unk, s_start, s_end] + vocab\n",
    "\n",
    "    # build inverse vocabulary\n",
    "    # i.e. if vocab[17] = 'cat', then inv_vocab['cat'] = 17\n",
    "    inv_vocab = {w: k for k, w in enumerate(vocab)}\n",
    "\n",
    "    def sentence_to_ix(sent):\n",
    "        sent = [s_start] + sent + [s_end]\n",
    "        sent_ix = [inv_vocab.get(w, inv_vocab[unk])\n",
    "                   for w in sent]\n",
    "        return sent_ix\n",
    "\n",
    "    # vectorize and save sentence as lists of ids\n",
    "    #############################################\n",
    "\n",
    "    train_ix = [(y, sentence_to_ix(sent)) for y, sent in train_sents]\n",
    "    valid_ix = [(y, sentence_to_ix(sent)) for y, sent in valid_sents]\n",
    "    test_ix = [(y, sentence_to_ix(sent)) for y, sent in test_sents]\n",
    "    unlab_ix = [(None, sentence_to_ix(sent)) for sent in unlabeled_sents]\n",
    "\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.makedirs(\"processed\")\n",
    "\n",
    "    with open(os.path.join(\"processed\", \"vocab.txt\"), \"w\") as f:\n",
    "        for w in vocab:\n",
    "            print(w, file=f)\n",
    "\n",
    "    with open(os.path.join(\"processed\", \"train_ix.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(train_ix, f)\n",
    "\n",
    "    with open(os.path.join(\"processed\", \"unlab_ix.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(unlab_ix, f)\n",
    "\n",
    "    with open(os.path.join(\"processed\", \"valid_ix.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(valid_ix, f)\n",
    "\n",
    "    with open(os.path.join(\"processed\", \"test_ix.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(test_ix, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4748\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 1.4s. Train loss:  0.68323 Valid accuracy:    58.25\n",
      "Epoch   1 took 1.5s. Train loss:  0.64951 Valid accuracy:    59.35\n",
      "Epoch   2 took 1.6s. Train loss:  0.60695 Valid accuracy:    59.61\n",
      "Epoch   3 took 1.4s. Train loss:  0.56651 Valid accuracy:    59.54\n",
      "Epoch   4 took 1.5s. Train loss:  0.53269 Valid accuracy:    59.75\n",
      "Epoch   5 took 1.6s. Train loss:  0.50511 Valid accuracy:    59.74\n",
      "Epoch   6 took 1.3s. Train loss:  0.48249 Valid accuracy:    59.51\n",
      "Epoch   7 took 1.4s. Train loss:  0.46377 Valid accuracy:    59.51\n",
      "Epoch   8 took 1.4s. Train loss:  0.44803 Valid accuracy:    59.30\n",
      "Epoch   9 took 1.2s. Train loss:  0.43460 Valid accuracy:    58.99\n",
      "Epoch  10 took 1.4s. Train loss:  0.42302 Valid accuracy:    58.75\n",
      "Epoch  11 took 1.5s. Train loss:  0.41297 Valid accuracy:    58.55\n",
      "Epoch  12 took 1.4s. Train loss:  0.40420 Valid accuracy:    58.32\n",
      "Epoch  13 took 1.4s. Train loss:  0.39643 Valid accuracy:    58.14\n",
      "Epoch  14 took 1.5s. Train loss:  0.38950 Valid accuracy:    58.03\n",
      "Epoch  15 took 1.4s. Train loss:  0.38328 Valid accuracy:    57.90\n",
      "Epoch  16 took 1.6s. Train loss:  0.37766 Valid accuracy:    57.90\n",
      "Epoch  17 took 1.6s. Train loss:  0.37253 Valid accuracy:    57.75\n",
      "Epoch  18 took 1.8s. Train loss:  0.36779 Valid accuracy:    57.65\n",
      "Epoch  19 took 1.8s. Train loss:  0.36333 Valid accuracy:    57.51\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "\n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 2.0s. Train loss:  0.68675 Valid accuracy:    56.88\n",
      "Epoch   1 took 2.2s. Train loss:  0.66798 Valid accuracy:    58.52\n",
      "Epoch   2 took 1.8s. Train loss:  0.64560 Valid accuracy:    59.46\n",
      "Epoch   3 took 1.6s. Train loss:  0.62291 Valid accuracy:    60.09\n",
      "Epoch   4 took 1.7s. Train loss:  0.59992 Valid accuracy:    60.09\n",
      "Epoch   5 took 1.8s. Train loss:  0.58040 Valid accuracy:    60.25\n",
      "Epoch   6 took 1.9s. Train loss:  0.56281 Valid accuracy:    60.22\n",
      "Epoch   7 took 2.2s. Train loss:  0.55240 Valid accuracy:    60.42\n",
      "Epoch   8 took 2.0s. Train loss:  0.53814 Valid accuracy:    60.46\n",
      "Epoch   9 took 2.1s. Train loss:  0.52960 Valid accuracy:    60.87\n",
      "Epoch  10 took 1.7s. Train loss:  0.51604 Valid accuracy:    60.61\n",
      "Epoch  11 took 1.8s. Train loss:  0.50569 Valid accuracy:    60.40\n",
      "Epoch  12 took 1.8s. Train loss:  0.49877 Valid accuracy:    60.65\n",
      "Epoch  13 took 2.0s. Train loss:  0.49228 Valid accuracy:    60.40\n",
      "Epoch  14 took 1.9s. Train loss:  0.48848 Valid accuracy:    60.50\n",
      "Epoch  15 took 1.9s. Train loss:  0.48189 Valid accuracy:    60.23\n",
      "Epoch  16 took 2.1s. Train loss:  0.47408 Valid accuracy:    60.12\n",
      "Epoch  17 took 1.8s. Train loss:  0.46681 Valid accuracy:    60.21\n",
      "Epoch  18 took 1.7s. Train loss:  0.46394 Valid accuracy:    60.25\n",
      "Epoch  19 took 1.6s. Train loss:  0.45455 Valid accuracy:    59.83\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "\n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 25.5s. Train perplexity:  238.159 Valid perplexity:  138.307\n",
      "Epoch   1 took 25.8s. Train perplexity:  136.312 Valid perplexity:  121.252\n",
      "Epoch   2 took 25.9s. Train perplexity:  121.573 Valid perplexity:  113.695\n",
      "Epoch   3 took 26.3s. Train perplexity:  112.886 Valid perplexity:  109.142\n",
      "Epoch   4 took 26.2s. Train perplexity:  106.760 Valid perplexity:  106.104\n",
      "Epoch   5 took 25.7s. Train perplexity:  102.091 Valid perplexity:  103.934\n",
      "Epoch   6 took 26.7s. Train perplexity:   98.366 Valid perplexity:  102.346\n",
      "Epoch   7 took 23.9s. Train perplexity:   95.297 Valid perplexity:  101.149\n",
      "Epoch   8 took 25.6s. Train perplexity:   92.706 Valid perplexity:  100.223\n",
      "Epoch   9 took 26.1s. Train perplexity:   90.487 Valid perplexity:   99.495\n",
      "Epoch  10 took 25.5s. Train perplexity:   88.565 Valid perplexity:   98.920\n",
      "Epoch  11 took 24.6s. Train perplexity:   86.882 Valid perplexity:   98.469\n",
      "Epoch  12 took 25.1s. Train perplexity:   85.392 Valid perplexity:   98.119\n",
      "Epoch  13 took 24.6s. Train perplexity:   84.061 Valid perplexity:   97.845\n",
      "Epoch  14 took 26.3s. Train perplexity:   82.860 Valid perplexity:   97.630\n",
      "Epoch  15 took 26.1s. Train perplexity:   81.771 Valid perplexity:   97.465\n",
      "Epoch  16 took 25.4s. Train perplexity:   80.777 Valid perplexity:   97.336\n",
      "Epoch  17 took 26.1s. Train perplexity:   79.866 Valid perplexity:   97.233\n",
      "Epoch  18 took 24.8s. Train perplexity:   79.032 Valid perplexity:   97.157\n",
      "Epoch  19 took 25.1s. Train perplexity:   78.267 Valid perplexity:   97.101\n",
      "Saving embeddings to embeds_baseline_lm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simplest possible neural language model:\n",
    "    use word w_i to predict word w_(i + 1)\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "from math import exp\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "USE_UNLABELED = False\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "train_perplexity_labeled_bigram = []\n",
    "valid_perplexity_labeled_bigram = []\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class SimpleNLM(object):\n",
    "\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.W_out = params.add_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "    def batch_loss(self, batch, train=True):\n",
    "\n",
    "        # load the parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "\n",
    "        W_out = dy.parameter(self.W_out)\n",
    "\n",
    "        losses = []\n",
    "        for _, sent in batch:\n",
    "            for i in range(1, len(sent)):\n",
    "                prev_word_ix = sent[i - 1]\n",
    "                curr_word_ix = sent[i]\n",
    "\n",
    "                ctx = dy.lookup(self.embed, prev_word_ix)\n",
    "\n",
    "                # hid is the hidden layer output, size=hidden_size\n",
    "                # compute b_hid + W_hid * ctx, but faster\n",
    "                hid = dy.affine_transform([b_hid, W_hid, ctx])\n",
    "                hid = dy.tanh(hid)\n",
    "\n",
    "                # out is the prediction of the next word, size=vocab_size\n",
    "                out = W_out * hid\n",
    "\n",
    "                # Intepretation: The model estimates that\n",
    "                # log P(curr_word=k | prev_word) ~ out[k]\n",
    "                # in other words,\n",
    "                # P(curr_word=k | prev_word) = exp(out[k]) / sum_j exp(out[j])\n",
    "                #                            = softmax(out)[k]\n",
    "\n",
    "                # We want to maximize the probability of the correct word.\n",
    "                # (equivalently, minimize the negative log-probability)\n",
    "\n",
    "                loss = dy.pickneglogsoftmax(out, curr_word_ix)\n",
    "                losses.append(loss)\n",
    "\n",
    "        # esum simply adds up the expressions in the list\n",
    "        return dy.esum(losses)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    if USE_UNLABELED:\n",
    "        __FIXME__\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    lm = SimpleNLM(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, batch_size=BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, batch_size=BATCH_SIZE)\n",
    "\n",
    "    n_train_words = sum(len(sent) for _, sent in train_ix)\n",
    "    n_valid_words = sum(len(sent) for _, sent in valid_ix)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate loss.\n",
    "        valid_loss = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=False)\n",
    "            valid_loss += loss.value()\n",
    "\n",
    "        toc = clock()\n",
    "        \n",
    "        # Task 4\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train perplexity: {:8.3f} \"\n",
    "               \"Valid perplexity: {:8.3f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            exp(total_loss / n_train_words),\n",
    "            exp(valid_loss / n_valid_words)\n",
    "            ))\n",
    "        train_perplexity_labeled_bigram.append(exp(total_loss / n_train_words))\n",
    "        valid_perplexity_labeled_bigram.append(exp(valid_loss / n_valid_words))\n",
    "        \n",
    "    # FIXME: make sure to update filenames when implementing ngram models\n",
    "    fn = \"embeds_baseline_lm\"\n",
    "    if USE_UNLABELED:\n",
    "        fn += \"_unlabeled\"\n",
    "\n",
    "    print(\"Saving embeddings to {}\".format(fn))\n",
    "    lm.embed.save(fn, \"/embed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 44.2s. Train perplexity:  167.196 Valid perplexity:  115.974\n",
      "Epoch   1 took 42.1s. Train perplexity:  114.827 Valid perplexity:  103.153\n",
      "Epoch   2 took 43.7s. Train perplexity:  103.955 Valid perplexity:   97.906\n",
      "Epoch   3 took 45.8s. Train perplexity:   98.158 Valid perplexity:   95.034\n",
      "Epoch   4 took 42.5s. Train perplexity:   94.392 Valid perplexity:   93.197\n",
      "Epoch   5 took 44.6s. Train perplexity:   91.665 Valid perplexity:   91.918\n",
      "Epoch   6 took 42.6s. Train perplexity:   89.571 Valid perplexity:   91.002\n",
      "Epoch   7 took 44.7s. Train perplexity:   87.922 Valid perplexity:   90.313\n",
      "Epoch   8 took 44.0s. Train perplexity:   86.576 Valid perplexity:   89.786\n",
      "Epoch   9 took 42.8s. Train perplexity:   85.450 Valid perplexity:   89.369\n",
      "Epoch  10 took 44.4s. Train perplexity:   84.486 Valid perplexity:   89.027\n",
      "Epoch  11 took 43.5s. Train perplexity:   83.651 Valid perplexity:   88.740\n",
      "Epoch  12 took 43.0s. Train perplexity:   82.924 Valid perplexity:   88.500\n",
      "Epoch  13 took 44.3s. Train perplexity:   82.287 Valid perplexity:   88.298\n",
      "Epoch  14 took 44.3s. Train perplexity:   81.723 Valid perplexity:   88.132\n",
      "Epoch  15 took 44.3s. Train perplexity:   81.219 Valid perplexity:   87.993\n",
      "Epoch  16 took 45.0s. Train perplexity:   80.764 Valid perplexity:   87.877\n",
      "Epoch  17 took 44.3s. Train perplexity:   80.352 Valid perplexity:   87.784\n",
      "Epoch  18 took 42.9s. Train perplexity:   79.976 Valid perplexity:   87.712\n",
      "Epoch  19 took 45.1s. Train perplexity:   79.631 Valid perplexity:   87.656\n",
      "Saving embeddings to embeds_baseline_lm_unlabeled\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Simplest possible neural language model:\n",
    "    use word w_i to predict word w_(i + 1)\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "from math import exp\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "USE_UNLABELED = True\n",
    "VOCAB_SIZE = len(vocab) #__FIXME__\n",
    "train_perplexity_all_bigram = []\n",
    "valid_perplexity_all_bigram = []\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class SimpleNLM(object):\n",
    "\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.W_out = params.add_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "    def batch_loss(self, batch, train=True):\n",
    "\n",
    "        # load the parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "\n",
    "        W_out = dy.parameter(self.W_out)\n",
    "\n",
    "        losses = []\n",
    "        for _, sent in batch:\n",
    "            for i in range(1, len(sent)):\n",
    "                prev_word_ix = sent[i - 1]\n",
    "                curr_word_ix = sent[i]\n",
    "\n",
    "                ctx = dy.lookup(self.embed, prev_word_ix)\n",
    "\n",
    "                # hid is the hidden layer output, size=hidden_size\n",
    "                # compute b_hid + W_hid * ctx, but faster\n",
    "                hid = dy.affine_transform([b_hid, W_hid, ctx])\n",
    "                hid = dy.tanh(hid)\n",
    "\n",
    "                # out is the prediction of the next word, size=vocab_size\n",
    "                out = W_out * hid\n",
    "\n",
    "                # Intepretation: The model estimates that\n",
    "                # log P(curr_word=k | prev_word) ~ out[k]\n",
    "                # in other words,\n",
    "                # P(curr_word=k | prev_word) = exp(out[k]) / sum_j exp(out[j])\n",
    "                #                            = softmax(out)[k]\n",
    "\n",
    "                # We want to maximize the probability of the correct word.\n",
    "                # (equivalently, minimize the negative log-probability)\n",
    "\n",
    "                loss = dy.pickneglogsoftmax(out, curr_word_ix)\n",
    "                losses.append(loss)\n",
    "\n",
    "        # esum simply adds up the expressions in the list\n",
    "        return dy.esum(losses)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "    if USE_UNLABELED:\n",
    "        #__FIXME__\n",
    "        with open(os.path.join('processed', 'unlab_ix.pkl'), 'rb') as f:\n",
    "            train_ix += pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    lm = SimpleNLM(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, batch_size=BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, batch_size=BATCH_SIZE)\n",
    "\n",
    "    n_train_words = sum(len(sent) for _, sent in train_ix)\n",
    "    n_valid_words = sum(len(sent) for _, sent in valid_ix)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate loss.\n",
    "        valid_loss = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=False)\n",
    "            valid_loss += loss.value()\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train perplexity: {:8.3f} \"\n",
    "               \"Valid perplexity: {:8.3f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            exp(total_loss / n_train_words),\n",
    "            exp(valid_loss / n_valid_words)\n",
    "            ))\n",
    "        train_perplexity_all_bigram.append(exp(total_loss / n_train_words))\n",
    "        valid_perplexity_all_bigram.append(exp(valid_loss / n_valid_words))\n",
    "        \n",
    "    # FIXME: make sure to update filenames when implementing ngram models\n",
    "    fn = \"embeds_baseline_lm\"\n",
    "    if USE_UNLABELED:\n",
    "        fn += \"_unlabeled\"\n",
    "\n",
    "    print(\"Saving embeddings to {}\".format(fn))\n",
    "    lm.embed.save(fn, \"/embed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAEWCAYAAAAuDD1eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnHNl5sHWOeecKzMPts4551yZ/T/C87/DilK2+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116a89320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compare the perplexities of training/validation bigram models using only labeled data \n",
    "plt.plot(train_perplexity_labeled_bigram, 'ro', label='Training Set')\n",
    "plt.plot(valid_perplexity_labeled_bigram, 'bs', label='Validation Set')\n",
    "plt.title('Training vs. Validation Perplexity On Bigram Models With Only Labeled Data')\n",
    "plt.ylabel('Perplexity For Bigram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEWCAYAAACZscV5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWecwLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e913518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the perplexities of training/validation bigram models using labeled + unlabeled data \n",
    "plt.plot(train_perplexity_all_bigram, 'ro', label='Training Set')\n",
    "plt.plot(valid_perplexity_all_bigram, 'bs', label='Validation Set')\n",
    "plt.title('Training vs. Validation Perplexity On Bigram Models  With Extra Unlabeled Data')\n",
    "plt.ylabel('Perplexity For Bigram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncc45V1Ke8TjnnCspz3icc86V1P8HRxPUwcokMGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137d80fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the validation perplexities with and without the extra unlabeled data\n",
    "plt.plot(valid_perplexity_labeled_bigram, 'ro', label='Only Labeled Data')\n",
    "plt.plot(valid_perplexity_all_bigram, 'bs', label='Use Extra Unlabeled Data')\n",
    "plt.title('Comparison Between Validation Perplexities On Bigram Models ')\n",
    "plt.ylabel('Perplexity For Bigram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 27.1s. Train perplexity:  194.813 Valid perplexity:  122.070\n",
      "Epoch   1 took 27.2s. Train perplexity:  116.136 Valid perplexity:  100.363\n",
      "Epoch   2 took 28.0s. Train perplexity:   99.143 Valid perplexity:   91.256\n",
      "Epoch   3 took 27.1s. Train perplexity:   89.661 Valid perplexity:   85.950\n",
      "Epoch   4 took 26.2s. Train perplexity:   83.153 Valid perplexity:   82.529\n",
      "Epoch   5 took 27.2s. Train perplexity:   78.328 Valid perplexity:   80.172\n",
      "Epoch   6 took 28.5s. Train perplexity:   74.522 Valid perplexity:   78.483\n",
      "Epoch   7 took 28.9s. Train perplexity:   71.433 Valid perplexity:   77.251\n",
      "Epoch   8 took 26.7s. Train perplexity:   68.854 Valid perplexity:   76.328\n",
      "Epoch   9 took 27.2s. Train perplexity:   66.640 Valid perplexity:   75.664\n",
      "Epoch  10 took 26.0s. Train perplexity:   64.719 Valid perplexity:   75.193\n",
      "Epoch  11 took 27.5s. Train perplexity:   63.021 Valid perplexity:   74.869\n",
      "Epoch  12 took 28.3s. Train perplexity:   61.498 Valid perplexity:   74.658\n",
      "Epoch  13 took 28.3s. Train perplexity:   60.114 Valid perplexity:   74.536\n",
      "Epoch  14 took 26.6s. Train perplexity:   58.851 Valid perplexity:   74.491\n",
      "Epoch  15 took 27.2s. Train perplexity:   57.692 Valid perplexity:   74.509\n",
      "Epoch  16 took 25.1s. Train perplexity:   56.624 Valid perplexity:   74.578\n",
      "Epoch  17 took 25.2s. Train perplexity:   55.634 Valid perplexity:   74.688\n",
      "Epoch  18 took 27.1s. Train perplexity:   54.716 Valid perplexity:   74.834\n",
      "Epoch  19 took 27.5s. Train perplexity:   53.859 Valid perplexity:   75.009\n",
      "Saving embeddings to embeds_baseline_lm_trigram\n"
     ]
    }
   ],
   "source": [
    "# Task 6 trigrams\n",
    "\"\"\"Simplest possible neural language model:\n",
    "    use word w_i to predict word w_(i + 1)\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "from math import exp\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "USE_UNLABELED = False\n",
    "VOCAB_SIZE = len(vocab) #__FIXME__\n",
    "train_perplexity_labeled_trigram = []\n",
    "valid_perplexity_labeled_trigram = []\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class SimpleNLM(object):\n",
    "\n",
    "    def __init__(self, n, params, vocab_size, hidden_dim):\n",
    "        self.ngram = n\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim * (n - 1)\n",
    "\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "\n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim * (n - 1)))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.W_out = params.add_parameters((vocab_size, hidden_dim))\n",
    "    \n",
    "    def batch_loss(self, batch, train=True):\n",
    "\n",
    "        # load the parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "\n",
    "        W_out = dy.parameter(self.W_out)\n",
    "        n = self.ngram\n",
    "        \n",
    "        losses = []\n",
    "        for _, sent in batch:\n",
    "            for i in range(n - 1, len(sent)):\n",
    "                #prev_word_ix = [] # Task 6: ck is with dimension n x (k - 1)\n",
    "                ctx = []\n",
    "                for j in range(i - n + 1, i):\n",
    "                    prev_word_ix = sent[j]\n",
    "                    ctx.append(dy.lookup(self.embed, prev_word_ix))\n",
    "                curr_word_ix = sent[i]\n",
    "                \n",
    "                ctx = dy.concatenate(ctx)\n",
    "                #ctx = dy.lookup(self.embed, prev_word_ix)\n",
    "\n",
    "                # hid is the hidden layer output, size=hidden_size\n",
    "                # compute b_hid + W_hid * ctx, but faster\n",
    "                hid = dy.affine_transform([b_hid, W_hid, ctx])\n",
    "                hid = dy.tanh(hid)\n",
    "\n",
    "                # out is the prediction of the next word, size=vocab_size\n",
    "                out = W_out * hid\n",
    "\n",
    "                # Intepretation: The model estimates that\n",
    "                # log P(curr_word=k | prev_word) ~ out[k]\n",
    "                # in other words,\n",
    "                # P(curr_word=k | prev_word) = exp(out[k]) / sum_j exp(out[j])\n",
    "                #                            = softmax(out)[k]\n",
    "\n",
    "                # We want to maximize the probability of the correct word.\n",
    "                # (equivalently, minimize the negative log-probability)\n",
    "\n",
    "                loss = dy.pickneglogsoftmax(out, curr_word_ix)\n",
    "                losses.append(loss)\n",
    "\n",
    "        # esum simply adds up the expressions in the list\n",
    "        return dy.esum(losses)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "    if USE_UNLABELED:\n",
    "        #__FIXME__\n",
    "        with open(os.path.join('processed', 'unlab_ix.pkl'), 'rb') as f:\n",
    "            train_ix += pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    lm = SimpleNLM(3, params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, batch_size=BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, batch_size=BATCH_SIZE)\n",
    "\n",
    "    n_train_words = sum(len(sent) for _, sent in train_ix)\n",
    "    n_valid_words = sum(len(sent) for _, sent in valid_ix)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate loss.\n",
    "        valid_loss = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=False)\n",
    "            valid_loss += loss.value()\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train perplexity: {:8.3f} \"\n",
    "               \"Valid perplexity: {:8.3f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            exp(total_loss / n_train_words),\n",
    "            exp(valid_loss / n_valid_words)\n",
    "            ))\n",
    "        train_perplexity_labeled_trigram.append(exp(total_loss / n_train_words))\n",
    "        valid_perplexity_labeled_trigram.append(exp(valid_loss / n_valid_words))\n",
    "        \n",
    "    # FIXME: make sure to update filenames when implementing ngram models\n",
    "    fn = \"embeds_baseline_lm_trigram\"\n",
    "    if USE_UNLABELED:\n",
    "        fn += \"_unlabeled\"\n",
    "\n",
    "    print(\"Saving embeddings to {}\".format(fn))\n",
    "    lm.embed.save(fn, \"/embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 46.2s. Train perplexity:  138.549 Valid perplexity:   92.709\n",
      "Epoch   1 took 46.9s. Train perplexity:   89.979 Valid perplexity:   80.110\n",
      "Epoch   2 took 42.8s. Train perplexity:   79.654 Valid perplexity:   74.992\n",
      "Epoch   3 took 46.4s. Train perplexity:   74.091 Valid perplexity:   72.117\n",
      "Epoch   4 took 46.9s. Train perplexity:   70.347 Valid perplexity:   70.264\n",
      "Epoch   5 took 47.5s. Train perplexity:   67.576 Valid perplexity:   69.016\n",
      "Epoch   6 took 47.2s. Train perplexity:   65.447 Valid perplexity:   68.132\n",
      "Epoch   7 took 45.8s. Train perplexity:   63.749 Valid perplexity:   67.491\n",
      "Epoch   8 took 45.1s. Train perplexity:   62.347 Valid perplexity:   67.015\n",
      "Epoch   9 took 44.0s. Train perplexity:   61.159 Valid perplexity:   66.653\n",
      "Epoch  10 took 45.6s. Train perplexity:   60.132 Valid perplexity:   66.373\n",
      "Epoch  11 took 48.2s. Train perplexity:   59.234 Valid perplexity:   66.159\n",
      "Epoch  12 took 47.3s. Train perplexity:   58.440 Valid perplexity:   65.998\n",
      "Epoch  13 took 47.0s. Train perplexity:   57.733 Valid perplexity:   65.881\n",
      "Epoch  14 took 48.1s. Train perplexity:   57.100 Valid perplexity:   65.796\n",
      "Epoch  15 took 46.8s. Train perplexity:   56.527 Valid perplexity:   65.741\n",
      "Epoch  16 took 46.0s. Train perplexity:   56.008 Valid perplexity:   65.708\n",
      "Epoch  17 took 47.0s. Train perplexity:   55.534 Valid perplexity:   65.692\n",
      "Epoch  18 took 47.2s. Train perplexity:   55.098 Valid perplexity:   65.689\n",
      "Epoch  19 took 49.6s. Train perplexity:   54.696 Valid perplexity:   65.701\n",
      "Saving embeddings to embeds_baseline_lm_trigram_unlabeled\n"
     ]
    }
   ],
   "source": [
    "# Task 6 trigrams with unlabeled data\n",
    "\n",
    "USE_UNLABELED = True\n",
    "train_perplexity_all_trigram = []\n",
    "valid_perplexity_all_trigram = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "    if USE_UNLABELED:\n",
    "        #__FIXME__\n",
    "        with open(os.path.join('processed', 'unlab_ix.pkl'), 'rb') as f:\n",
    "            train_ix += pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    lm = SimpleNLM(3, params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, batch_size=BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, batch_size=BATCH_SIZE)\n",
    "\n",
    "    n_train_words = sum(len(sent) for _, sent in train_ix)\n",
    "    n_valid_words = sum(len(sent) for _, sent in valid_ix)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate loss.\n",
    "        valid_loss = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=False)\n",
    "            valid_loss += loss.value()\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train perplexity: {:8.3f} \"\n",
    "               \"Valid perplexity: {:8.3f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            exp(total_loss / n_train_words),\n",
    "            exp(valid_loss / n_valid_words)\n",
    "            ))\n",
    "        train_perplexity_all_trigram.append(exp(total_loss / n_train_words))\n",
    "        valid_perplexity_all_trigram.append(exp(valid_loss / n_valid_words))\n",
    "        \n",
    "    # FIXME: make sure to update filenames when implementing ngram models\n",
    "    fn = \"embeds_baseline_lm_trigram\"\n",
    "    if USE_UNLABELED:\n",
    "        fn += \"_unlabeled\"\n",
    "\n",
    "    print(\"Saving embeddings to {}\".format(fn))\n",
    "    lm.embed.save(fn, \"/embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAEWCAYAAAAn550kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8VHX9x/HXG1CQTRQRBGTJXFgEhBtqrqQ/1wr3VCzX\nUH+mZaVpWmpFWZqaZSUpuSGKZmq/ckUNrZQuCsiigrLvoiyCIsjn98f3OzB3mLl3Zu69c+ZePs/H\nYx4z853zPed7Zs6cz3yXOV+ZGc4555wrnSZJF8A555zb1njwdc4550rMg69zzjlXYh58nXPOuRLz\n4Oucc86VmAdf55xzrsRKGnwlNZX0kaRudblsYyDpAUnXx8eHS5qWz7JFbKdRvK+SXpF0Th2s521J\nh9RBkcqCpBsk/S7pcpSSpIckXZvnskskHVzP5Tlf0t+qef0YSbPqswxZtvmqpLNKuL2i9zGpvKVW\nbfCNJ+nUbZOkj9OeDyt0Y2b2mZm1NrN5dbls0iQdLGmNpJZZXpsi6aJC1mdmL5lZnzoqW5UgVZ/v\nq6QFacfIEkmjJLWq6+3UJTPb28xeBpD0M0n31GZ9kr4q6b+S1kpaEX8odS5iPU1r+P59Lcf+XGdm\n36rNPtQXSRdJMkm/yEj/Wkz/Y1Jlq46kuZKGpj0/IpY3M+0DSU3M7G4z+0pMbxGX7VrLMpwoqTIe\nV+9Luk/SbrVZZ57bvUjS8/W9nVJI+yzWxu/Q+5Kek3RSAeuos+BebfCNJ+nWZtYamAd8JS1tdJaC\nNauLQjU0ZvYKsBSo8iFKGgDsBTycRLkScmw8Xr4AHAhcXegKGupxJOl04H7g10B7oC/wGfCKpHaF\nrCvtR1Lq+7eI+N7G21bHVG3ftxK977OAMyWln3vOBt4pwbaLNR44NO35ocBbWdJeMbNNdb3xWNH5\nM/ArwnHVD2gKjJfUtq63tw3YO36negFjgLsk/aDUhahVs3OsKTwsaYykNcBZkg6MTRwrJS2WdLuk\n7eLyzeIvjx7x+QPx9adizfE/knoWumx8/VhJ70haJem3kv6lLM2SknaPNYgd09K+IGlZ3OZeksbH\n9bwv6cE83477gG9kpH0D+JuZfSipiaRHY41wpaSXJPXK8b4eKWlO2vNBkibF/R4DNE97rb2kf0ha\nLulDSX+T1CW+9ktCAPxj/KV3W5b3tV18b5dLmiPpakmKr10g6Z+Sbo1lfk/SUfm8GWY2H3iaEIBS\n2/lzPCYWSPpJ6gQctzM+fr4fANempf0+fhYzJA3Jtb24/FvxPXhK0u4x/ZC4b6n3ZGBcZs/4fIFC\nM/+XgSuBYfG9mijpDEmvZWznSkl/ybL9JsDNwA1m9pCZfWJmi4HzgE+By2r7nmbZ5o2SHozfwTXA\n6THtroz3ZX58D65UWrNrjvwHSXotlm1RLGezuHyq5nCRpHclrZZ0raS9JU2In9NoVR/E5wKzgSFx\nnR2BAcBTGft2sqTpsRzPpz6v+NpgSZPj9+EBYPuMvCcqtDitlPSypN453r+DJL0R92OJMmrkaTKD\n7yHAL7OkjY/rTa8tjo/3b8fj6oS07f8wfi4LlaMlMb6XNwM/NrOx8bhaRPjBAvCttG2Oi9+hlfHz\nOTLL+lrG/U1/P7tKWqcCfyBKujB+59ZImiXpvCzL3KDQIjBb0qlp6TsonI/mx/f+t5KaZ+aPy+4u\n6QmF8/F7SmtJlNQqHnMrJb0J7Jdv+c1suZmNInw3r1P8IZNrvyS1B/4KfE5bWqDaV/edqakAed2A\nOcCRGWk/I5xYvkII5DsQajz7A82AzxF+0X4rLt8MMKBHfP4A8D5QAWxHqCE+UMSyuwJrgKHxte8C\nG4BzcuzLeODctOe3Ar+Ljx8BfhD3pwVwUJ7vT4+4zc7xeVNgMfDl+LwJcA7QJq73d0BlWv4HgOvj\n4yOBOfFxc2BBPEC2A06P20kt2wE4Mb73bYHHgEfT1vtK+vuQ5X19MOZpEz+vWcDZ8bUL4rbOi/tz\nKTC/mvdgAXB4fNyNUDu4Lj7/G/B7oCXQEZgInJ+2nY3AxXE7O6Slpfb7TOBDoF3mfgEnA28De8f9\nux54Oa1cvwSei9ueDlyUo8w/A+5Je20HYCWwZ1ram8DQLPveN76vu2d5bUSqPIW+p9nKmZZ2I7Ae\nOI4t378bgbvi6/sBq4ED4nF0e3xPD64m/2DCd7gpsEc8Hi6Ky7eI+/gI0DqufwPwDNAd2BmYCXwt\nxz5cBDwf9/3emPZd4DeEAPPHmLYv4ft8OCGw/ih+bs1iGRcD/xuPi2Fxn66NeQ+Irw+K+zCccA5q\nFl9fkrb/bwCnxsdtgP1zlHvvuI3WcZvLY7mWpKWtAwan72fGe9Y1bX3HxPftmpj3xLi/rbNse0DM\nv1uW134JvJi2zQ2EH/xNgcuJ55D4+qvAWfHxKMKPxNRrPwAeqe4zy/HaV4GegAjnrI+BPmn7uBH4\nRXyvjozvUc/4+h+AR4F2wI7xGLouLe+stPPom7GM2xNaEucBh8XXbwPGxfX0JJwHZuUo71afRUxv\nFdOH5LlfszLy5/zOVPudrmmBtA3MIXvwfaGGfN9PfbBkD6h/zPgwpxax7HlUPdmK8AXMFXwvAp6N\nj5sQmvS+GJ8/GA+MLvm+N2nrfQm4Mj4+ltAU3SzHsrvE/WuVtn/Zgu+XgPmA0vJOSC2bZb0VwPK0\n5zmDL+GLvxHYK+31S9hy4rgAeCvttbYx7y45tr0A+IgQsOYSfmC0ALrEA7h52rJfB55L2857Geu6\nIMt+vw6ckblfhMB6dsY+rk99hoQv7STCl/jvWcp8eNrxfE/G638inqgIJ8L3ge2y7Pvh8b3Z6vMm\n1E5mFPOeZitnWtqNxOM4Iy0VfH8O/DljW5uoGnyfrWG7VwFj4uPUyWtQ2uvTgG+nPb8DuLGa793z\nhEC3lHDSm0QIlOnBdwRwX1q+poSAdwBwFDA7Y72vsyX4/hm4JuP1ucTAStXgO4EQANvn8d1eAhxN\naEkaF9MeT0tbw5YAn0/wXQU0SUtbDQzIst0j42fWJMtr3wHeTNvm1LTXdo7bTf1YTQ++h5EWQAjf\ni69W95nV9P7EZZ8GLkzbx0+AFmmvPwlcQfh+fkraOZbQEjIjLe+stLLOzNjODcAf4uNFpH0vCD/W\nCwq+8bWVwMl57lfW9Wf7zlR3q4vRzvPTn0jaR9LfY1PCauAnhECTy5K0x+sIvyQLXbZzejksvAML\nqlnPI8AhsclrCPCJmf07vvY9QlCqlPSmpLOrWU+mewlBhXj/oJlthM0DaH4Vm01WE34dQfXvTWrf\nFsR9SpmbeiCptaS7JM2L630hj3Wm7Eo4sc1NS5tLCJYpme85VP8ZfdnM2plZdzP7lpl9QqgVNQeW\nxqaZlYSTdMe0fPOzrCvbfmcbvNQduCNt3e8TTlhdAczsU8Jn05dwki/EvYTaFcBZwMNmtiHLcu/H\n+2yDYHZLex0Kf0+rk+19S8n8XqwmnPRz5pfUW6HZfmk8nn7M1sfT0rTHH2d5Xu2+mNkaQm3lOkLA\nmpil3HPTlv8MWEg4Ljuz9Xc7/fjtDvwwdSzE46EDVY/plLMJ/afvxGbDo6spdqrp+VDg5Zj2Slra\nv1Pf9Twtt6r9w7nOfe8TKhMds7xW7HE1Hmiq0EU4IK7nqSzLVUthcOGE2Ky8klBRSD9Wlsfvf0rq\n+9uZcI6dlvYZPU44H2XqDvTI+Dy/C3RS6OrpRNVjeG6WddS0H60Ite8P8tyvzPz5fGe2UhfB1zKe\n3wlMBT5vZm1jQVQH26nOYuKJFkCSyP5lA8DMVhCC1KmE5swxaa8tNrMLzGw3Qi1wpNL6lmvwKKE/\n4DDgBMKJO+UbhOa9LxE+6M+nilvDOqvsW5T+N6ErCE0kg+P7/aWMZTM/n3TLCAOCumese2ENZSrU\nfMLJYOcYmNuZWVsz61dDObPt96Ic6z8/bd3tzGwHM3sNQOFvVdcC9wC3KI5ByGKrMlgYTIekgwjH\nyv058k6PZTs1PVFSU8JAvHE58tVWdZ9v5veiLeHYqy7/nwg1yT3i8fQT6uf7ex+hVSzb+7mItGMy\nvoddCMdlTd+H+YT+0fRjoaWZPZa5ETObYWZfI5z0bwcek7R95nJRKvgewpbg+3Ja2vgc+ar7fPIx\nlfDjps6Oq/iD9j7Cj8mvAw/l+EGZUwxYjwA/BXY1s3aEc2r6sbKLpBZpz1Pf38WEFrc90j6jHc2s\nfZZNzSe0FKV/nm3M7MT442UpsHvGNgp1IuFH48Q89ivb51nUd6Y+/ufbhvDreq3CgKIL62Ebmf4P\nGCjpK7Gj+9uEX7vVeZDwy/ek+BgASacpDs4hNEUYIUDVKP6if4wQdGea2aS0l9sQmkJXEPoeR+Sz\nTsKv6yaSvqUwWOo0YGDGetcBH8YBAT/OyL+U0JebrbwbCD8Yfh5r0D0JfUUP5Fm2vFgYfPVP4GZJ\nbRUGn31e0qE1ZN0tbb9PJ/SnPJ1luT8C18TjLTW465T4WISg+0dC98QHhGarbJYSfmVnfnHuJ3RF\nfGRmr+bYx02EAVvXK/x1poXCX0FGEfopf1PDvtaHscDJCgMKtyecFGoajdsGWGVmH0nqA3yznsr2\nHKEJOdvfix4GTpR0aPyhdBXhe1NJCHItFAYYNZN0BqH2mjISuFRShYLWsSaT7W+A35DUPtasVxG+\n67mC5Xi2jGdJHQOvA32Ag8kRfM1sfVx31u9gTWJt+gfATyWdKqm5wl/X7iW0WhX7n+77gNOAM+Lj\n6jSJx3Pq1pxwTG9H+AG/SdJXCV0v6bYDfiRpe0lfAv4H+Es874wCfiNpl/g57S7pf7JsO/Xj9ztx\n280k9ZOUOgeOJXz3d5TUnTAWIC8Kg6XOJvQb/yy2DNW0X0uBXSWltygU9Z2pj+D7PUJQW0OoBdf7\n32zMbCnwNeAWwpd0D8JgivXVZHsc6A3MM7P0C1rsD/xX0lpCIL3E4n9iFS7IkPX/lWnuJfxqzzyg\n/0z41beI0E/2b/IQv7wnEj7QD+Pjx9MWuYVQm1kR15nZfHQbcEZssrklyyb+l9D/MocQIO/NUva6\ncBahj286YT8eITQZVeffhJPbB4RBVCeb2YeZC5nZI4T34ZHY7DOF0BcHoYlqJ0IfuREGvQ2X9MUs\n23uY0D/8gaQJaen3EZqsc9V6U+UYTTj2r4hlnkb4Ih+crdz1zczeiGX5K1tqjauo/ntxOXCBpI8I\nXQP18v218Feq580ssxkcM5sCnE84fywHjiAMcttoZh8TvgP/SziOjicM5kvl/Reh3+9Owo/ndwgt\nFtmC6pcJo5DXEAYGnVZNDfBNYC2hv3lt3NYGQp91c0L/cS4/JhybK+PJvCBmdi/h/biKsM9vxpcO\nNrOVha4vrvNdwuCkNWZWXdkhdM19nHZba2bvE1ou/kY495wA/CMj3xxCDXcJIdiea2bvxde+QzgX\nVhKOyafZ0hqYXs4NhBbDLxKalJcTfgingt+1hKb3ecDfye/c9XY8vt8htEhebGY/j9urab8mE/qu\n58bPc2eK/M6oapda4xCbZBYBp1i8gIJrWCRdQBggcngZlKUV4ZdwXzObnXR5iiVpJ8KPgs4W/gbl\ntmEKf6OcbmY/S7os26JGc21nhSuPtItNIj8iDLuv6Redc/m4BPhXQwy8scl1h9hMdgvwmgdeJ+nz\nhJr/n5Muy7aq0QRfQr/Le4RmiaOBE2OTrXNFk7SA8P/j7yddliKdSmj2W0AYtFTwZWFd4yLpV4Ru\nuZ+YWV0PrnR5apTNzs4551w5a0w1X+ecc65BaJAXsE9RuH7vfYQ/oBsw0sx+E0egPUy4itMcwijG\nD2OeqwkjBz8DLjOzZ6rbxi677GI9evSor11wzrlGaeLEie+bWU1/+dxmNehm5/g/yt3M7HVJbQjX\nCz6B8HeSD8zsRklXATuZ2Q8ULrA+hnAtzs6ES93tFf/nl1VFRYVVVlbW964451yjImmimVUkXY5y\n1aCbnePVqF6Pj9cAMwiDSoay5epS9xICMjH9ITNbH0euziIEYuecc65kGnTwTacwRd5+wGtAx7S/\nUyxhy3VRu1D1OqCpEaCZ6xquMHF15fLly+utzM4557ZNjSL4xv8w/gX4TrxE2GbxqkYFta2b2Ugz\nqzCzig4dvMvCOedc3WrQA64A4rVf/wKMTrt4+lJJu5nZ4tgvvCymL6TqRbi7UveTCDjn6siGDRtY\nsGABn3zySc0Lu0S0aNGCrl27st12ueYrcdk06OAbL4B/N2EeyPTrFj9JuMbujfH+ibT0B+M1jjsD\ne+JXwXKubC1YsIA2bdrQo0cPtp7vwiXNzFixYgULFiygZ898J39z0PCbnQ8iTIn1JUmT4u04QtD9\nH0kzCZNR3wgQJ1AYS7i4/9OESRPymrGoYKNHQ48e0KRJuB89ul4241xj9sknn9C+fXsPvGVKEu3b\nt/eWiSI06JpvnGs117fyiBx5RpD/dH7FGT0ahg+HdXE+67lzw3OAYX51P+cK4YG3vPnnU5yGXvMt\nT9dcsyXwpqxbF9Kdc85t8zz41od58wpLd86VpRUrVjBgwAAGDBhAp06d6NKly+bnn376aV7rOPfc\nc3n77berXeaOO+5gdB11TT3xxBMMGDCA/v3707t3b+66665ql3/hhRd49dVX62TbLn8Nutm5bHXr\nFpqas6U75+rP6NGhhWnevPB9GzGiVl097du3Z9KkSQBcf/31tG7dmu9/v+oEV2aGmdGkSfa6zJ//\nXPOsfZdccknRZUy3fv16Lr74YiorK+ncuTPr169nbrZzUZoXXniBXXbZhQMOOKBOyuDy4zXf+jBi\nBLRsWTWtZcuQ7pyrH6mxFnPngtmWsRb1MNhx1qxZ9O7dm2HDhtGnTx8WL17M8OHDqaiooE+fPvzk\nJz/ZvOzBBx/MpEmT2LhxI+3ateOqq66if//+HHjggSxbFv4Fee2113LbbbdtXv6qq65i8ODB7L33\n3vz73/8GYO3atZx88sn07t2bU045hYqKis0/DFJWrVqFmbHzzjsD0Lx5c/baay8Ali5dykknnURF\nRQWDBw/m1Vdf5d133+Wuu+7ipptuYsCAAZu35eqfB9/6MGwYjBwJ3buDFO5HjvTBVs7VpxKPtXjr\nrbe4/PLLmT59Ol26dOHGG2+ksrKSyZMn89xzzzF9+vSt8qxatYrDDjuMyZMnc+CBBzJq1Kis6zYz\nJkyYwE033bQ5kP/2t7+lU6dOTJ8+nR/96Ee88cYbW+XbddddOfroo+nevTtnnnkmY8aMYdOmTQBc\ndtllXHnllVRWVjJ27FguuOAC9thjDy644AKuuOIKJk2axBe/+MU6fIdcdbzZub4MG+bB1rlSKvFY\niz322IOKii3zBowZM4a7776bjRs3smjRIqZPn07v3r2r5Nlhhx049thjARg0aBAvv/xy1nWfdNJJ\nm5eZM2cOAK+88go/+MEPAOjfvz99+vTJmveee+5hypQpPP/889x4442MGzeOu+66i+eff75K3/OH\nH37Ixx9/XNzOu1rz4OucaxxKPNaiVatWmx/PnDmT3/zmN0yYMIF27dpx1llnZf3v6/bbb7/5cdOm\nTdm4cWPWdTdv3rzGZarTr18/+vXrx5lnnkmvXr246667Ntem08vgkuPNzs65xiHBsRarV6+mTZs2\ntG3blsWLF/PMM9VOE16Ugw46iLFjxwLw5ptvZm3WXr16NePHj9/8fNKkSXTv3h2AI488kjvuuKPK\nawBt2rRhzZo1dV5eVz0Pvs65xiHBsRYDBw6kd+/e7LPPPnzjG9/goIMOqvNtXHrppSxcuJDevXtz\nww030Lt3b3bccccqy5gZv/jFL9h7770ZMGAAP/vZzzb3K99xxx3861//ol+/fvTu3Zs//elPAAwd\nOpSxY8ey3377+YCrElKY9MflUlFRYZWVlUkXw7lt0owZM+jVq1fSxSgLGzduZOPGjbRo0YKZM2dy\n1FFHMXPmTJo1S773MNvnJGmimVXkyLLNS/5Tc845V6OPPvqII444go0bN2Jm3HnnnWUReF1x/JNz\nzrkGoF27dkycODHpYrg64n2+zjnnXIl58HXOOedKzIOvc845V2IefJ1zzrkS8+DrnHM5DBkyZKsL\nZtx2221cfPHF1eZr3bo1AIsWLeKUU07Juszhhx9OTX9jvO2221iXdr3q4447jpUrV+ZT9Gq9/fbb\nHH744QwYMIBevXoxfPjwapefM2cODz74YK2367bw4OucaxQ6dQrX1si8depU/DrPOOMMHnrooSpp\nDz30EGeccUZe+Tt37syjjz5a9PYzg+8//vEP2rVrV/T6Ui677DIuv/xyJk2axIwZM7j00kurXd6D\nb93z4OucaxSWLi0sPR+nnHIKf//73/n000+BEIQWLVrEIYccsvl/twMHDmTffffliSee2Cr/nDlz\n6Nu3LwAff/wxp59+Or169eLEE0+sMqnBxRdfvHk6wuuuuw6A22+/nUWLFjFkyBCGDBkCQI8ePXj/\n/fcBuOWWW+jbty99+/bdPB3hnDlz6NWrF9/85jfp06cPRx11VNbJExYvXkzXrl03P993330B+Oyz\nz7jiiiv4whe+QL9+/bjzzjsBuOqqq3j55ZcZMGAAt956a/FvqNsiNRF0Q7wBo4BlwNS0tAHAq8Ak\noBIYnPba1cAs4G3g6Hy2MWjQIHPOJWP69Ol5Lxsm8c1+q43jjz/eHn/8cTMz+8UvfmHf+973zMxs\nw4YNtmrVKjMzW758ue2xxx62adMmMzNr1aqVmZnNnj3b+vTpY2Zmv/71r+3cc881M7PJkydb06ZN\n7b///a+Zma1YscLMzDZu3GiHHXaYTZ482czMunfvbsuXL99cltTzyspK69u3r3300Ue2Zs0a6927\nt73++us2e/Zsa9q0qb3xxhtmZnbqqafa/fffv9U+jRo1ytq2bWvHHHOM3XLLLfbhhx+amdmdd95p\nP/3pT83M7JNPPrFBgwbZe++9Zy+++KIdf/zxOd+jbJ8TUGllECfK9dbQa773AMdkpP0KuMHMBgA/\njs+R1Bs4HegT8/xeUtPSFdU51xClNz2nNzmbGT/84Q/p168fRx55JAsXLmRpNdXs8ePHc9ZZZwFb\nZh1KGTt2LAMHDmS//fZj2rRpWSdNSPfKK69w4okn0qpVK1q3bs1JJ520eXrCnj17MmDAAKDqlITp\nzj33XGbMmMGpp57KSy+9xAEHHMD69et59tlnue+++xgwYAD7778/K1asYObMmfm/WS5vDTr4mtl4\n4IPMZKBtfLwjsCg+Hgo8ZGbrzWw2oQY8uCQFdc41WEOHDmXcuHG8/vrrrFu3jkGDBgEwevRoli9f\nzsSJE5k0aRIdO3bMOo1gTWbPns3NN9/MuHHjmDJlCscff3xR60lJTUcI1U9J2LlzZ8477zyeeOIJ\nmjVrxtSpUzEzfvvb3zJp0iQmTZrE7NmzOeqoo4oui8utQQffHL4D3CRpPnAzoakZoAswP225BTFt\nK5KGS6qUVLl8+fJ6Laxzrry1bt2aIUOGcN5551UZaLVq1Sp23XVXtttuO1588UXmZptLOM2hhx66\nedDS1KlTmTJlChCmAWzVqhU77rgjS5cu5amnntqcJ9d0f4cccgiPP/4469atY+3atfz1r3/lkEMO\nyXufnn76aTZs2ADAkiVLWLFiBV26dOHoo4/mD3/4w+bX3nnnHdauXevTDtaDxhh8LwYuN7PdgcuB\nuwtdgZmNNLMKM6vo0KFDnRfQOVf3OnYsLL0QZ5xxBpMnT64SfIcNG0ZlZSX77rsv9913H/vss0+1\n67j44ov56KOP6NWrFz/+8Y8316D79+/Pfvvtxz777MOZZ55ZZTrC4cOHc8wxx2wecJUycOBAzjnn\nHAYPHsz+++/PBRdcwH777Zf3/jz77LP07duX/v37c/TRR3PTTTfRqVMnLrjgAnr37s3AgQPp27cv\nF154IRs3bqRfv340bdqU/v37+4CrOtLgpxSU1AP4PzPrG5+vAtqZmUkSsMrM2kq6GsDMfhGXewa4\n3sz+U936fUpB55LjUwo2DD6lYOEaY813EXBYfPwlIDVa4EngdEnNJfUE9gQmJFA+55xz27gGPaWg\npDHA4cAukhYA1wHfBH4jqRnwCTAcwMymSRoLTAc2ApeY2WeJFNw559w2reyCr6QdgS5mVv1Ye8DM\ncl1mZlCO5UcAI2pRPOdciZkZoQfJlaOG3nWZlLJodpY0TlJbSTsRLo5xv6Sbki6Xcy5ZLVq0YMWK\nFX6CL1NmxooVK2jRokXSRWlwyqXmu7OZrZZ0PvCAmf1I0hTgiqQL5pxLTteuXVmwYAH+l7/y1aJF\niyqXqnT5KZfg20xSB+BUwlWpnHOO7bbbjp49eyZdDOfqXFk0OxP6Yf8JzDOzCZI+B8xOuEzOOedc\nvSiLmq+ZPQQ8lPb8PcLlIJ1zzrlGJ9HgK+lWwrWYszKz75awOM4551xJJF3znZrw9p1zzrmSSzT4\nmlmV6y5Lam5m65Mqj3POOVcKZTHgStJgSW8SLwUpqb+k3yZcLOecc65elEXwBW4HvgysADCzycCQ\nanM455xzDVS5BN8mZpY5GaZfd9k551yjlPSAq5T5kgYDJqkpcCnwTsJlcs455+pFudR8Lwa+C3QD\nlgIHxDTnnHOu0SmLmq+ZLQNOT7oczjnnXCn4RTacc865Eku62XkqMA1oAxwIzI+3/YHWCZbLOeec\nqzdlcZENSd8EDjazjfH5HYSJFpxzzrlGJ+mab8pOVK3ptgR2TqgszjnnXL0qiwFXwE3AJEnPAyJc\nYONnyRbJOeecqx9lUfM1s7uAg4CngL8Dh5jZqJrySRolaZmkqRnpl0p6S9I0Sb9KS79a0ixJb0s6\nuq73wznnnMtHudR8AfoDX4iPPwYW5pHnHuB3wH2pBElDCHMB9zez9ZJ2jem9CX9n6gN0Bp6XtJeZ\n+ZW0nHPOlVRZ1HwljQCuBN6Ltysk1djsbGbjgQ8yki8GbkzNjhT/QwwhID9kZuvNbDYwCxhcR7vg\nnHPO5a0sgi/wFeAIMxtpZiOBo4CvFrmuvYBDJL0m6Z+SUrXpLoS/MaUsiGlbkTRcUqWkyuXLlxdZ\nDOeccy5PbfylAAAeK0lEQVS7cgm+AG3THrepxXqaEUZKHwBcAYyVpEJWEH8EVJhZRYcOHWpRFOec\nc25r5dLn+yvgdUnjCKOdDwd+VOS6FgCPmZkBEyRtAnYh9CHvnrZcV/LrV3bOOefqVFnUfM3sAeBg\n4B+E0c6HmtmDRa7uceJcwJL2ArYH3geeBE6X1FxST2BPYEJty+6cc84VKulrO/fLSJoV79tLam9m\nU2rIP4ZQS95F0gLgOmAUMCr+/ehT4OxYC54maSwwHdgIXOIjnZ1zziVBIS4ltPHQJDydLSOW0/tm\nzcwOLX2pqqqoqLDKysqki+Gccw2KpIlmVpF0OcpV0n2+VwInASuBMcATZrYu2SI555xz9SvRPl8z\nu9nMvgh8j9AH+09JD2ZpjnbOOecajXIZcDUTeBj4P8LAq97Jlsg555yrP0kPuOpGuOTjicASQgDu\nZWZrkyyXc845V5+S7vOdA0wB/kro990VOD91TQwzuz2xkjnnnHP1JOng+3PAYjl2SbgszjnnXEkk\nGnzN7Nokt++cc84loSwGXDnnnHPbEg++zjnnXIl58HXOOedKLOkBVwBIagucBfQgrUxm9t2kyuSc\nc87Vl7IIvoTZjF4H3gQ2JVwW55xzrl6VS/BtaWaXJV0I55xzrhTKpc/3QUnnSuogqW3qlnShnHPO\nufpQLjXfj4DbgJ8SLrpBvO+WWImcc865elIuwfcHwJ5mtizpgjjnnHP1rVyanWcBq5MuhHPOOVcK\n5VLzXQ28IekFYH0q0f9q5JxzrjEql+D7j3hzzjnnGr2yCL5mdncx+SSNAr4MLDOzvhmvfQ+4Gehg\nZu/HtKuB84HPgMvM7JlaFdw555wrQln0+UraQ9JDkqZIeid1yyPrPcAxWda3O3AUMC8trTdwOtAn\n5vm9pKZ1sgPOOedcAcoi+BKC6J8BAccCY4GHa8pkZuOBD7K8dCtwJVv+tgQwFHjIzNab2WzCIK/B\ntSu2c845V7hyCb4tU03AZvZunOf32GJWJGkosNDMJme81AWYn/Z8QUzLto7hkiolVS5fvryYYjjn\nnHM5lUWfL7BeUhPgXUkXAQuBNoWuRFJL4IeEJueimdlIYCRARUWF1bC4c845V5ByCb6XA62Ay4AR\nQFvgvCLWswfQE5gsCaAr8LqkwYSAvnvasl1jmnPOOVdSiQffOOjpRDN7DVgDfL3YdZnZm8Cuaeue\nA1SY2fuSniRcQ/oWoDOwJzChNmV3zjnnipF4n6+ZfQYMKSavpDHAf4C9JS2QdH4125lGGMg1HXga\nuCRu2znnnCupxGu+0URJjwGPAGtTiWb2ZHWZzOyMGl7vkfF8BKFZ2znnnEtMuQTfNoSge1xamgHV\nBl/nnHOuISqL4GtmRffzOueccw1NWQTfOAgq0yqg0sz+XuryOOecc/Up8QFXURtgf8JFMOYDXyD8\nZeh/Jf06yYI555xzda0sar5AX+AQM9sIIOl3wHjgEGAy8L0Ey+acc87VqXKp+e4MtEx7vgOwcwzG\n67Nncc455xqmcqn53gJMkjSOMLnC4cBNkloBLyVYLuecc67OlUXwNbM7Jf2d0O8LcIOZpSZB+G5C\nxXLOOefqRaLNzpL2jPf9CE3PM+Ntp5jmnHPONTpJ13yvAs4H7sjymgGHlrY4zjnnXP1LNPia2flx\nKsErzOzVJMvinHPOlUrio53NbBPwx6TL4ZxzzpVK4sE3elHS0KQL4ZxzzpVC0n2+KecA35a0HviY\n8HcjM7OdEy2Vc845Vw8SDb6SupnZPGCXJMvhnHPOlVLSzc6PA5jZZ9luCZfNOeecqxdJB18lvP16\n0akTSFvfOnVKumTOOefKQdJ9vl0k3Z7rRTO7rJSFqStLlxaW7pxzbtuSdPD9GJiYcBmcc865kko6\n+K4ws3uLzSxpFPBlYJmZ9Y1pNwFfAT4F3gXONbOV8bWrCVfU+gy4zMyeqWX5nXPOuYIl3ef7aS3z\n3wMck5H2HNDXzPoB7wBXA0jqDZwO9Il5fi+paS2375xzzhUs0eBrZgfUMv944IOMtGfjPMAArwJd\n4+OhwENmtt7MZgOzgMG12b5zzjlXjKRrvvXtPOCp+LgLMD/ttQUxbSuShkuqlFS5fPnygjfasWNh\n6c4557YtjTb4SroG2AiMLjSvmY00swozq+jQoUPB216yBMy2vi1ZUvCqnHPONUKJB19JTSW9Vcfr\nPIcwEGuYmVlMXgjsnrZY15jmnHPOlVTiwTdeyeptSd3qYn2SjgGuBL5qZuvSXnoSOF1Sc0k9gT2B\nCXWxzXoxejT06AFNmoT70QVX4J1zzpWppP9qlLITME3SBGBtKtHMvlpdJkljgMOBXSQtAK4jjG5u\nDjwnCeBVM7vIzKZJGgtMJzRHX1K2l7AcPRqGD4d18bfD3LnhOcCwYcmVyznnXJ3QllbZBAshHZYt\n3cz+WeqyZKqoqLDKysrSbrRHjxBwM3XvDnPmlLYszjlXBEkTzawi6XKUq7Ko+ZrZPyV1BL4QkyaY\n2bIky5SoefMKS3fOOdegJN7nCyDpNEL/66nAacBrkk5JtlQJ6paj+ztXunPOuQalLIIvcA3wBTM7\n28y+Qbj4xY8SLlNyRoyAli2rprVsGdKdc841eOUSfJtkNDOvoHzKVnrDhsHIkaGPVwr3I0f6YCvn\nnGskyqLPF3ha0jPAmPj8a8A/EixP8oYN82DrnHONVFkEXzO7QtLJwEExaaSZ/TXJMjnnnHP1JdHg\nK+kAM3sVwMz+AvwlyfI455xzpZB0v+rvUw8k/SfJgjjnnHOlknTwVdrjFomVwjnnnCuhpPt8m0ja\nifAjIPV4c0A2sw9y5nTOOecaqKSD747ARLYE3NfTXjPgcyUvkXPOOVfPEg2+ZtYjye0755xzSUi6\nz9c555zb5njwdc4550rMg69zzjlXYmURfCX9WlKfpMvhnHPOlUJZBF9gBjBS0muSLpK0Y9IFcs45\n5+pLWQRfM7vLzA4CvgH0AKZIelDSkGRL5pxzztW9sgi+AJKaAvvE2/vAZOC7kh5KtGDOOedcHSuL\n4CvpVuAt4Djg52Y2yMx+aWZfAfarJt8oScskTU1L21nSc5Jmxvud0l67WtIsSW9LOro+96k2OnUK\n0/hm3jp1Srpkzjnn6kJZBF9gCjDAzC40swkZrw2uJt89wDEZaVcB48xsT2BcfI6k3sDpQJ+Y5/ex\ntl12li4tLD2r0aOhRw9o0iTcjx5dByVzzjlXF8ol+J5lZmvTEySNAzCzVbkymdl4IPP6z0OBe+Pj\ne4ET0tIfMrP1ZjYbmEX1gb3hGj0ahg+HuXPBLNwPH+4B2DnnykSiwVdSC0k7A7tI2ik2Ge8sqQfQ\npcjVdjSzxfHxEqBjfNwFmJ+23IJc25A0XFKlpMrly5cXWYwEXXMNrFtXNW3dupDunHMucUlPrHAh\n8B2gM1UnVVgN/K62Kzczk2RF5BsJjASoqKgoOH/i5s0rLN0551xJJVrzNbPfmFlP4Ptm1jPt1t/M\nig2+SyXtBhDvl8X0hcDuact1jWmNT7duhaU755wrqaSbnb8UHy6UdFLmrcjVPgmcHR+fDTyRln66\npOaSegJ7ApmDu8pCx46FpW9lxAho2bJqWsuWId0551zikm52Pgx4AfhKltcMeKy6zJLGAIcT+owX\nANcBNwJjJZ0PzAVOAzCzaZLGAtOBjcAlZvZZHe1HnVqypJYrGDYs3F9zTWhq7tYtBN5UunPOuUTJ\nrOF1aZZSRUWFVVZWJl0M55xrUCRNNLOKpMtRrsrir0aS7k+/nrOk7qm/GjnnnHONTVkEX+AV4DVJ\nx0n6JvAccFvCZXLOOefqRdJ9vgCY2Z2SpgEvEq7rvJ+Z1bbn0znnnCtLZVHzlfR1YBRhVqN7gH9I\n6p9ooRowvza0c86Vt7Ko+QInAweb2TJgjKS/Ei4NOSDZYjVMdXJtaOecc/WmLIKvmZ2Q8XyCpMZ5\n3WXnnHPbvHJpdt5L0rjU1ICS+gFXJlysbZvPiuScc/WmLIIv8CfgamADgJlNIUz/55LgsyI551y9\nKpfg2zLLPL4bEymJ81mRnHOunpVL8H1f0h6ES0oi6RRgcfVZXC61vja0z4rknHP1qiwGXAGXEKbw\n20fSQmA2cFayRWq4an1t6G7dQlNztnTnnHO1VhbB18zeA46U1ApoYmZrki7TtqzTyhksZYet0juu\n/Bi/8olzztVeosFX0ndzpANgZreUtEAOgKWrtg681aU755wrTNI13zYJb98555wruUSDr5ndkOT2\nnXPOuSSUxWhnSZ+T9DdJyyUtk/SEpM8lXS5XC36RDuecy6ksgi/wIDAW2A3oDDwCjEm0RK5ondp9\njM4ahubOQbYp3J81jE7tPk66aM45VxbKJfi2NLP7zWxjvD0AtEi6UNuq2v5P2AdsOedc9ZIecJXy\nlKSrgIcIF9r4GmFawZ0BzOyDJAu3ran1/4Sdc85Vq1yC72nx/sKM9NMJwbjg/l9JlwMXxPxvAucC\nLYGHgR7AHOA0M/uwqBK7etOpU/bpDzt29B8GzrnGIfFmZ0lNgLPMrGeOWzGBtwtwGVBhZn2BpoRA\nfhUwzsz2BMbF567M+HzEzrnGLvHga2abgN/Vw6qbATtIakao8S4ChgL3xtfvBU7Ikdc1YJ06gbT1\nrVOnpEvmnHNB4sE3GifpZKUubVVLZrYQuBmYR5igYZWZPQt0NLPUhA1LgKxDiCQNl1QpqXL58uV1\nUaRtSq0ndqglrzk758pduQTfCwl/L/pU0mpJayStLnZlknYi1HJ7Ev661EpSlYkazMyIsyhlMrOR\nZlZhZhUdOnQothjbrCVLwjTAmbeG0l/rNWfnXH0ri+BrZm3MrImZbWdmbePztrVY5ZHAbDNbbmYb\ngMeALwJLJe0GEO+X1b70rrGpbc3Zg7dzriZlEXwVnCXpR/H57pIG12KV84ADJLWMTdlHADOAJ4Gz\n4zJnA0/UptyufnTMMXdSrvRy48HbOVeTsgi+wO+BA4Ez4/OPgDuKXZmZvQY8CrxO+JtRE8J8wTcC\n/yNpJqF2fGMtyuzqyZLuB2Boq9uS7gckXbSSSDp4e/DfdvlnXzrlEnz3N7NLgE8A4n9vt6/NCs3s\nOjPbx8z6mtnXzWy9ma0wsyPMbE8zO9Iv3lGmRoyAli2rprVsGdLzkPSAr6TVNnjXJn/Sgd/z1y6/\nD1YsnXIJvhskNSUOgJLUAdiUbJFcYoYNg5EjoXv3cObo3j08HzYsr+xLfj0aa9mqas25ZSuW/Non\nd6hvSQZ+z+/BsyFRGPSbcCGkYYRLSg4k/P/2FOBaM3sk0YIBFRUVVllZmXQxXCF69IC5c7dO794d\n5sypMXttr7BV3R/m8vm6NeT8Dbnsnr/2+auuSxPNrKKwXNuOsri8pJmNljSRMDBKwAlmNiPhYrmG\nat68wtIz1PYvUR075g7ezjkHCTc7S2oh6TuSfgccBtxpZr/zwOtqpVu3wtKzqcV8xLX9n/O23mft\n3LYg6T7fe4EKwojkYwlXpXKudmo5YIvRo2H48NB0bRbuhw8vKADXRtLB24P/tss/+9JJOvj2NrOz\nzOxOQj/voQmXxzUGtRywxTXXwLp1VdPWrQvpDUBtg3dt8icd+D1/7fI39KvTNSSJDriS9LqZDcz1\nvBz4gKttUJMm2UeXSLDJB+E7lw8fcFW9pGu+/eO1nFdLWgP0q4trOztXKwn3GTvnGr9Eg6+ZNY3X\nck5dz7lZHV3b2bniNfA+Y+dc+Uu65utc+dnG+4ydc/XPg69z2QwbFi7IsWlTuM838EKt/2cMeLO1\nc42cB1/n6lpt+4y92dq5Rs+Dr3N1rbZ9xt5s7Vyj58HXubpW2z5jb7Z2rtEri2s7O9foDBtWWD9x\num7dsk8MUWizdar2nGq2TpXLOZc4r/k6V27Kodnaa87O1SsPvs6Vm6SbrX3Al3P1zoOvc+WoNn91\nqu1o69rWnL3W7FyNPPg619jUttm6NjVnrzU7l5dGG3wltZP0qKS3JM2QdKCknSU9J2lmvN8p6XI6\nV+dq22xdm5qz9zc7l5dGG3yB3wBPm9k+QH9gBnAVMM7M9gTGxefONT61abauTc3Z+5udy0ujDL6S\ndiTMDXw3gJl9amYrgaHAvXGxe4ETkimhc2WsNjXnpPubwWvOrkFIdD7f+iJpADASmE6o9U4Evg0s\nNLN2cRkBH6aeZ+QfDgwH6Nat26C52f5z6ZzbWuZ/jCHUmvMN3rWdS7m223d1xufzrV6jrPkSLh4y\nEPiDme0HrCWjidnCr46svzzMbKSZVZhZRYcOHeq9sM41Gkn2N4PXnF2D0ViD7wJggZm9Fp8/SgjG\nSyXtBhDvlyVUPucar6T6m6E8+pw9eLs8NMrga2ZLgPmS9o5JRxCaoJ8Ezo5pZwNPJFA851wuDb3m\n7MHb5alR9vnC5n7fu4DtgfeAcwk/NsYC3YC5wGlm9kF166moqLDKysp6Lq1zrk4k3efco0f263J3\n7x5aAWrSiPqsvc+3eo2y5gtgZpNiv20/MzvBzD40sxVmdoSZ7WlmR9YUeJ1zDUzSNefaNnt7n/U2\no9EGX+fcNirJPuekg7c3ezcYHnydcy6ltjXnpIN3OfRZu7w02j7fuuJ9vs65goweHYLdvHkhaI4Y\nkX/wbuh91lU26X2+1fGar3PO1aXaNHs39D5rlzcPvs45V04acp+1y5sHX+ecayyS7rN2eWuWdAGc\nc87VoWHDiv9PcCpfsX3WLm8efJ1zzm1Rm+Dt8ubNzs4551yJefB1zjnnSsyDr3POOVdiHnydc865\nEvPg65xzzpWYX16yBpLWAG/XYhW7AO97fs+/DeZvyGX3/LXPv7eZtalF/kbN/2pUs7drc31SSZWe\n3/Nvi/kbctk9f93kLzbvtsCbnZ1zzrkS8+DrnHPOlZgH35qN9Pye3/M3uG17/oafv1HzAVfOOedc\niXnN1znnnCsxD77OOedciXnwzYOkUyVNk7RJUt5D7yUdI+ltSbMkXVXgNkdJWiZpauElBkm7S3pR\n0vRY9m8XmL+FpAmSJsf8NxRRhqaS3pD0f4XmjfnnSHpT0qRC/7YgqZ2kRyW9JWmGpAMLyLt33Gbq\ntlrSdwrc/uXxfZsqaYykFgXm/3bMOy2fbWc7XiTtLOk5STPj/U4F5s/7uM+R/6b4/k+R9FdJ7QrM\n/9OYd5KkZyV1LiR/2mvfk2SSdilw+9dLWph2HBxX6PYlXRrfg2mSflXg9h9O2/YcSZMKzD9A0qup\n74+kwQXm7y/pP/E7+DdJbXPkzXquKeT42yaZmd9quAG9gL2Bl4CKPPM0Bd4FPgdsD0wGehewzUOB\ngcDUIsu8GzAwPm4DvFPg9gW0jo+3A14DDiiwDN8FHgT+r8h9mAPsUmTee4EL4uPtgXZFrqcpsATo\nXkCeLsBsYIf4fCxwTgH5+wJTgZaE/+I/D3y+0OMF+BVwVXx8FfDLAvPnfdznyH8U0Cw+/mUR22+b\n9vgy4I+F5I/puwPPAHOrO5ZybP964Pt5fmbZ8g+Jn13z+HzXQsuf9vqvgR8XuP1ngWPj4+OAlwrM\n/1/gsPj4POCnOfJmPdcUcvxtizev+ebBzGaYWaFXuRoMzDKz98zsU+AhYGgB2xwPfFDgNtPzLzaz\n1+PjNcAMQlDIN7+Z2Ufx6XbxlvfoPEldgeOBu/IudB2RtCPhZHI3gJl9amYri1zdEcC7Zja3wHzN\ngB0kNSME0UUF5O0FvGZm68xsI/BP4KTqMuQ4XoYSfoQQ708oJH8hx32O/M/G8gO8CnQtMP/qtKet\nqOb4q+b7citwZXV5a8iflxz5LwZuNLP1cZllxWxfkoDTgDEF5jcgVVvdkWqOwRz59wLGx8fPASfn\nyJvrXJP38bct8uBbf7oA89OeL6CA4FeXJPUA9iPUXgvJ1zQ2dS0DnjOzQvLfRjjpbSpkmxkMeF7S\nREnDC8jXE1gO/Dk2e98lqVWRZTidak562ZjZQuBmYB6wGFhlZs8WsIqpwCGS2ktqSai17F5IGaKO\nZrY4Pl4CdCxiHXXlPOCpQjNJGiFpPjAM+HGBeYcCC81scqHbTXNpbPoeVUSz6V6Ez/E1Sf+U9IUi\ny3AIsNTMZhaY7zvATfH9uxm4usD809hSYTiVPI7BjHNNOR1/ZceDbyTp+djHlnnLu7ZajiS1Bv4C\nfCejJlEjM/vMzAYQaiyDJfXNc5tfBpaZ2cSCC1zVwXH7xwKXSDo0z3zNCE1ofzCz/YC1hGavgkja\nHvgq8EiB+XYinLR6Ap2BVpLOyje/mc0gNNM+CzwNTAI+K6QMWdZpFNByUZckXQNsBEYXmtfMrjGz\n3WPebxWwzZbADykwYGf4A6HbaADhR9SvC8zfDNgZOAC4Ahgba7GFOoMCfwBGFwOXx/fvcmJLUAHO\nA/5X0kRCc/Kn1S1c3bkmyeOvXHnwjczsSDPrm+X2RJGrXEjVX4pdY1rJSNqO8GUYbWaPFbue2GT7\nInBMnlkOAr4qaQ6huf1Lkh4oYrsL4/0y4K+Epvx8LAAWpNXUHyUE40IdC7xuZksLzHckMNvMlpvZ\nBuAx4IuFrMDM7jazQWZ2KPAhoR+tUEsl7QYQ73M2e9YXSecAXwaGxRNwsUaTo9kzhz0IP34mx+Ow\nK/C6pE75rsDMlsYfoJuAP5H/8ZeyAHgsduFMILQC5Rz0lU3stjgJeLjAbQOcTTj2IPyALKj8ZvaW\nmR1lZoMIwf/dasqZ7VyT+PFXzjz41p//AntK6hlrUKcDT5Zq4/EX9t3ADDO7pYj8HRRHp0raAfgf\n4K188prZ1WbW1cx6EPb7BTPLu+YXt9lKUpvUY8LgnbxGfpvZEmC+pL1j0hHA9EK2HxVb45gHHCCp\nZfwcjiD0g+VN0q7xvhvh5PtgEeV4knACJt4X+0OyKJKOIXQ9fNXM1hWRf8+0p0PJ8/gDMLM3zWxX\nM+sRj8MFhEFBSwrY/m5pT08kz+MvzeOEQVdI2osw8K/QWYKOBN4yswUF5oPQx3tYfPwloKBm67Rj\nsAlwLfDHHMvlOtckevyVvfoYxdXYboQv3gJgPbAUeCbPfMcRaizvAtcUuM0xhKauDXHb5xeY/2BC\nM88UQrPlJOC4AvL3A96I+adSzUjLGtZzOEWMdiY0902Ot2lFvH8DgMpY/seBnQrM3wpYAexY5H7f\nQAgWU4H7iSNeC8j/MuEHw2TgiGKOF6A9MI5w0n0e2LnA/Hkf9znyzyKMe0gdf9WNVs6W/y/x/ZsC\n/A3oUuz3hRpGzufY/v3Am3H7TwK7FZh/e+CBuA+vA18qtPzAPcBFRX7+BwMT4zH0GjCowPzfJpy/\n3gFuJF4RMUverOeaQo6/bfHml5d0zjnnSsybnZ1zzrkS8+DrnHPOlZgHX+ecc67EPPg655xzJebB\n1znnnCsxD77OFUDSZ6o641HBV86qZt09lMcsVgqz7axL/Q8zpn1UXZ66LoNzrnaaJV0A5xqYjy1c\n8jJp7wPfA36QdEHSSWpmWyZTcM7l4DVf5+pAnG/1V3Hu0wmSPh/Te0h6IV6cf1y8YhWSOirMcTs5\n3lKXn2wq6U9xXtRn49XFshkFfE3SzhnlqFJzlfR9SdfHxy9JulVhbtcZkr4g6TGF+VZ/lraaZpJG\nx2UejddJRtKgOEHAREnPpF068CVJtynMuVzQvNHObas8+DpXmB0ymp2/lvbaKjPbF/gdYVYngN8C\n95pZP8L1iW+P6bcD/zSz/oTrTk+L6XsCd5hZH2Alua9n/BEhABca7D41swrCpQKfAC4hzB98jqT2\ncZm9gd+bWS9gNeHi+tvFfTnFwrV+RwEj0ta7vZlVmFmhkw84t03yZmfnClNds/OYtPtb4+MD2TIX\n7/2ECcYhXGv3GxBmjwJWxdmQZpvZpLjMRKBHNWW5HZgk6eYCyp+6vvibwDSLU75Jeo8wEchKYL6Z\n/Ssu9wBhIvunCUH6uTgxT1PC5QhTirnwv3PbLA++ztUdy/G4EOvTHn8G5Gp2xsxWSnqQUHtN2UjV\nFq0WOda/KWNbm9hyPsgsuwEiBOsDcxRnba5yOue25s3OztWdr6Xd/yc+/jdhZicIE8K/HB+PI8y3\niqSmknYscpu3ABeyJXAuBXaV1F5Sc8J0foXqJikVZM8EXgHeBjqk0iVtJ6lPkWV2bpvnwde5wmT2\n+d6Y9tpOkqYQ+mEvj2mXAufG9K+zpY/228AQSW8Smpd7F1MYM3ufMNdx8/h8A/ATYALwHAVMw5fm\nbeASSTOAnYA/mNmnwCnALyVNJsxcU9Acxc65LXxWI+fqQJywvSIGQ+ecq5bXfJ1zzrkS85qvc845\nV2Je83XOOedKzIOvc845V2IefJ1zzrkS8+DrnHPOlZgHX+ecc67E/h8oBVYS2dO7zgAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13afcdb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 6 Trigram Model\n",
    "# Compare the perplexities of training/validation trigram models using only labeled data \n",
    "plt.plot(train_perplexity_labeled_trigram, 'ro', label='Training Set')\n",
    "plt.plot(valid_perplexity_labeled_trigram, 'bs', label='Validation Set')\n",
    "plt.title('Training vs. Validation Perplexity On Trigram Models With Only Labeled Data')\n",
    "plt.ylabel('Perplexity For Trigram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEWCAYAAACZscV5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYHFW5x/HvLwuELBD2sGWRy5KFEGCMIIsgXAE3BEHB\ncGU1wkXwooIo7hpFUUQUlQgIQgCBq6BXUXYBFTCBhCUBg5JAIAkhQAKELfDeP87ppDPpmUzPTFJd\nM7/P8/TTXcupequ6ut6qU9V1FBGYmZlZufQoOgAzMzOrnxO4mZlZCTmBm5mZlZATuJmZWQk5gZuZ\nmZWQE7iZmVkJrdEELqmnpJckDe7McbsCSZdL+lr+vLekh9sybjvm0yXWq6S7JB3dCdN5VNKenRBS\nQ5D0dUk/KTqONUnSVZK+1MZx50naYzXHc5yk37cy/ABJj63OGBqZpLslHdnGcdv9fRVVdk1qNYHn\nHX3l9ZakV6q6x9U7s4h4MyL6R8QTnTlu0STtIelFSX1rDHtA0gn1TC8ibo+IkZ0U2wqJbnWuV0lz\nqraReZIultSvs+fTmSJiu4i4E0DStyRd0pHpSfqgpH9IelnSwnywtXk7ptNzFb+/j7awPF+NiE91\nZBlWF0knSApJ32nW/6O5/8+Liq01kmZLOqiqe98cb/N+z0nqEREXRcQHcv8+edwtOzD/uyW92mx7\nuKYN5baXtLS9861nmvUcRJVdXtbX8j7/xbyP/6ak/nVMo1MOEFpN4HlH3z8i+gNPAB+o6jepRlC9\nOhpQGUXEXcB84JDq/pLGANsCvy4iroIcmLeXtwO7AV+odwJl3Y4kHQ5cBvwA2BAYBbwJ3CVpYD3T\nqjrQqvz+niav2/xaaZvq6HpbQ+v9MeBjkqr3PUcB/1wD826vO4C9qrr3Ah6p0e+uiHhrNcVwfPX2\nEBGHdcZEy/pbawDfjIgBwMbAJ4B9gDsl9VmTQXSoCj2fsfxa0pWSXgSOlLRbPmJ8QdJcSedJ6p3H\n75WPRofm7svz8BvykczfJQ2rd9w8/EBJ/5S0SNKPJf1VNapYJW2Vz2TWq+r3dknP5HluK+mOPJ1n\nJV3RxtXxK+Djzfp9HPh9RDwvqYeka/OR1wuSbpc0vIX1up+kWVXdu0iampf7SmDtqmEbSvqjpAWS\nnpf0e0lb5GHfJSXRn+ej9nNrrNeBed0ukDRL0hckKQ87XtJfJP0wx/xvSe9py8qIiCeBP5GSWGU+\nv8zbxBxJ36jsxPN87sjf73PAl6r6/TR/FzMk7dPS/PL4j+R1cIOkrXL/PfOyVdbJznmcbXL3HKVL\nFu8HTgfG5XU1RdIRku5pNp/TJf1vjfn3AL4PfD0iroqIVyNiLnAs8DpwSkfXaY15niXpivwbfBE4\nPPe7sNl6eTKvg9NVdeTfQvndJd2TY3s6x9krj185mzxB0r8kLZb0JUnbSbo3f0+T1HpSmA08Ttrh\nIWlTYAxwQ7Nl+7Ck6TmOmyvfVx42VtK0/Hu4HFirWdmDlc6KXpB0p6QRLay/3SXdn5djnprVDFRp\nnsD3BL5bo98debonSLq5qizAo3m7+lDV/L+Yv5en1I4azTyNr+bfSeW3dKrSvmKtPO/qmpydcmy3\nSjpf0vPAGUpn1bcr1SAskHSppAHtiadq+W/Jv+cX8rayXwvjtmXe78y/7eckTZRUvf9r63fdU9KX\n8+/t2bydDqwafpykJ3IMp7V1WfPv/B7gA8CWwJGrWi6l2pNNgBvz93KK0n75fyXNz8tym6Tt2hJA\nm17ALGC/Zv2+Rdo5fYB0MLAO6czrHUAv4G2kI+tP5fF7AQEMzd2XA88CTUBv0pnq5e0YdxPgReCg\nPOwzwBvA0S0syx3AMVXdPwR+kj9fA3w+L08fYPc2rp+heZ6b5+6ewFzg/bm7B3A0MCBP9yfA5Kry\nlwNfy5/3A2blz2sDc0gJoDdweJ5PZdyNgYPzul8X+A1wbdV076peDzXW6xW5zID8fT0GHJWHHZ/n\ndWxenpOBJ1tZB3OAvfPnwaSzlK/m7t8DPwX6ApsCU4DjquazFDgxz2edqn6V5f4Y8DwwsPlyAR8G\nHgW2y8v3NeDOqri+C9yU5z0dOKGFmL8FXFI1bB3gBWCbqn4PAgfVWPZReb1uVWPYhEo89a7TWnFW\n9TsLeA14L8t/f2cBF+bhOwGLgV3zdnReXqd7tFJ+LOk33BPYOm8PJ+Tx++RlvAbon6f/BvBnYAiw\nATAT+GgLy3ACcHNe9ktzv88APyId/Pw899uB9Hvem5Scv5y/t145xrnAf+ftYlxepi/lsrvm4bvk\nZRhP2gf1ysPnVS3//cBh+fMA4B0txL1dnkf/PM8FOa55Vf2WAGOrl7PZOtuyanoH5PV2Zi57cF7e\n/i3M/27gyBaG9QLuAc4ARpJ+IyPzsO2BpTW+g6Wks8bKb2174N15mQbl+Z3VwvxWmmbuf1XVd3BC\nXr6P53mcSt6fNV+eVc07r+P7gc1J+7p/tPO7/jxwZ55OH+AS4JdVv5MXSSc7awPnU/U7aW1Zm/W/\nmuXbdVuWa4+q7l55ffXP8f0MuHuV+4VVjVA1g1nUTuC3rqLc54BrqoJsnpR/XjXuB4GH2jHusay4\nw1b+YltK4CcAN+bPPUjVk+/M3VfklbdFW9dN1XRvB07Pnw8kVav3amHcjfLy9atavloJ/N3Ak4Cq\nyt5bGbfGdJuABVXdLSZw0s5jKbBt1fCTWL7zOR54pGrYurnsRi3Mew7wEinpzSYdpPQBtgBeAdau\nGve/gJuq5vPvZtM6vsZy3wcc0Xy5SMn5qGbL+FrlOyT9iKaSku8fasS8d9X2fEmz4b8gnVVDOlN8\nFuhdY9n3zutmpe8b+BQwoz3rtFacVf3OIm/HzfpVEvi3yTupqnm9xYoJ/MZVzPcM4Mr8uZKMdqka\n/jDw6aru82l5519J4ANIv41++XvZhRUT+ATgV1XlepKS5q7Ae4DHm033Ppbv1H8JnNls+GxycmbF\nnfq9pCS6YRt+2/OA/Uk7+Vtyv+uq+r3I8sTRlgS+COhR1W8xMKaFed8NvEz6XVVeZ1YN34aUuB8F\nTq3q31IC/+cqlvVw4O8tDGtrAn+oatgGeR0MrFqelg5IVph3Xu/V+69DgIfb8V0/TtXJGDCMdNAl\n0u/kkqph61H1O2ltWZv1P5dU49rW5ao5/Tx8UI6hT2vfVWfchf5kdUeuOvhDrpJaDHyDlKxaMq/q\n8xLSEUi9425eHUekNTCnlelcA+yZq+/2AV6NiL/lYZ8lJbbJkh6UdFQr02nuUlJiIr9fERFLYVkV\nzvdyFc5i0pkNtL5uKss2Jy9TxezKB0n9JV2Yq38WA7e2YZoVm5B2jrOr+s0mJdyK5uscWv+O3h8R\nAyNiSER8KiJeJZ2drQ1UqodeIO3oN60q92SNadVa7lo3hA0Bzq+a9rOkjX9LgIh4nfTdjCIlinpc\nSjrLg1Q99uuIeKPGeM/m981qDNusajjUv05bU2u9VTT/XSwmJY4Wy0saoXQJYn7enr7CytvT/KrP\nr9TobnVZIuJF4Bbgq6SkN6VG3LOrxn8TeIq0XW7Oyr/t6u13CPDFyraQt4eNWXGbrjgKGA38U+my\nwf6thF2pRt+LdCYH6SCy0u9vld96Gy2IFa+Xr2rf98n8u6q8JlQGRMRM4G+k7eyCNsy7+Xe+uaRr\nclX+YuBCWt6HLAV6aMV7GCDtM6t/F23axts47+p4q/cBbfquJQnYCvhj1Xj3k07eNmTl38kiVv6d\ntMUWwHN1LFd1jL0k/aAqPzxCOrjYsLUZdkYCj2bdFwAPAf8REeuSdgDqhPm0Zi55Zw3LvrBaP1gA\nImIhKdEdRqqavbJq2NyIOD4iNiOdjU5U1bX2VbgWeJukdwEfIu38Kz5Oqqp8N+kI7z8q4a5imiss\nW1b9F7DTSEeTY/P6fnezcZt/P9WeId1kNaTZtJ9aRUz1epL0I96gage0bkSMXkWctZb76Ramf1yz\nHdw6ka5NofSXuS+Rqs3OUb4no4aVYoh0gyKSdidtK5e1UHZ6jm2Fm4sk9SSdNdzSQrmOau37bf67\nWJe07bVW/hekM9qt8/b0DVbP7/dXpNq5Wuvzaaq2ybwOtyBtl6v6PTwJfKXZttA3In7TfCYRMSMi\nPko6kD0P+E2+dlxLJYHvyfIEfmdVvztaKNfa99MpJB1Cuuzwd6D6On5L827e/2zSGf6o/J0fT8vf\neeXgaUiz/sNY8UCqrdoy762qPlfvA9r0XeeTgKeAdzcbt09EPEvappbNQ+n+qOa/k1bl6+l7s3zb\nWNVyNf8OjgH+k3RCuR6ppgNW8dtbHf8DH0A6enlZ6SatT66GeTT3f8DOkj6gdAPNp0lHYq25gnQE\nfkj+DICkjyjf8ESqqgpSklulfGbxG1LinhkRU6sGDyBV6y4kXYudsPIUarqLdMT7qXyU9hFg52bT\nXQI8L2lD0gFTtfmka9u14n2DdNDx7XwmP4x0veryNsbWJpFuaPsL8H1J6yrd0PcfkvZaRdHNqpb7\ncNI12T/VGO/nwJl5e6vcMHdo/ixS4v456VLLc8DXW5jffGBoLlPtMtJllZci4u4WlvEt0k1wX1P6\nW1QfSZsBF5OuM/5oFcu6OlwNfFjpJs21SMl4VXdJDwAWRcRLkkaSrpWuDjeRqsNr/XXs18DBkvbK\nB1tnkH43k0mJso/SjVK9JB1BOouumAicLKlJSX+lv/bV+ovnxyVtmM/wF5F+6y0lvTtYfn9PZRu4\nj3TdeQ9aSOAR8Vqeds3fYEdJGkRah8eQThIOl7RvHvwM6Sa2VT3zYQDp0tfiPO5nWhox16hdD3xH\n0vqSeivdLDyE9J3Wqy3zPkXSZpI2Im0LlX9gtPm7Jq2js7T85tZNJH0gD7saOETSO5RukPsWq/6d\nkKfTR9JY0jp5muX7zlUtV/P98gDgVdJ23i/HsEqrI4F/lpQYXySdja/2v1BFxHzgo8A5pBWwNamK\n5LVWil0HjACeiIjqh6a8A/iHpJdJyfikyP+ZVnroR83/31a5lLQx/6pZ/1+SvuCnSdcN/0Yb5B3A\nwaQd6fP583VVo5xDOmJbmKd5Q7NJnAsckauOzqkxi/8m3Yg4i5RkL60Re2c4krRhTictxzWk6zyt\n+RtpB/kc6ca0D0fE881HiohrSOvhmlz99ADp2iSkH876pHsGgnQj4XhJ76wxv1+Trpc/J+neqv6/\nIlW/t3T2XYljEmnbPy3H/DCpanGPWnGvbhFxf47ltyw/e11E67+LU4HjJb1EusyxWn6/kf4md3Ou\nrmw+7AHgONL+YwGwL+nGwaUR8QrpN/DfpO3ofaQbJCtl/0q68fEC0gH4P0k1J7US8/tJd4e/SDpz\n/UgLl0cg3T/xMun6+8t5Xm+QruGvTbqe3pKvkLbNFyR9sJXxWnOhVvwfeGX/cTHpUt0teT94AvBL\nSQPzNvc9YEqe95hW4tuDtG38FljpXxbNfIKUbB4mJaJjSX9xXNiO5WrLvK8CbiPdIPkgaZnq/a6/\nR7r/4tb8ff+NfCKUfyefJZ3MzCH9ZfrZGtOo9uU8nWdJ38FfgT3zAU5blmsCMCF/L58CLiJt6/Py\nMt61ivkD+QahriZXuT0NHBr5IR1WLpKOJ93osncDxNKPdDYzKiIeLzqe9pK0PunAYvNIf3EzsxLr\nMs9CV3o84cBcBfJl0g0VrR0Vm7XVScBfy5i8c5XiOkpPiToHuMfJ26xr6EpP4dmDdC27F6lq5+Bc\n/WzWbpLmkA4GD1rVuA3qMFLVf5AOaNv1wBAzazxdsgrdzMysq+syVehmZmbdSVeqQi/MRhttFEOH\nDi06DDOzUpkyZcqzEbGqv/xaC5zAO8HQoUOZPHly0WGYmZWKpPY8/MUyV6GbmZmVkBO4mZlZCXX5\nBC7pYqW2vh+qMeyzSu0bb1TV7wuSHstPXWutcQMzM7PCdIdr4JeQmrVc4fGg+Zm47yE9Nq/SbwSp\n2beRpBZqbpa0bX5Wspk1oDfeeIM5c+bw6quvrnpkK0SfPn3Ycsst6d27pXaErD26fAKPiDskDa0x\n6Iekxieur+p3EHBVfgDM45IeA8aSWvkxswY0Z84cBgwYwNChQ1m5HRorWkSwcOFC5syZw7BhbW3Y\n0dqiy1eh1yLpIOCpiJjWbNAWrNj27BxaaJZU0nhJkyVNXrBgQfsCmTQJhg6FHj3S+6RJ7ZuOWTf2\n6quvsuGGGzp5NyhJbLjhhq4hWQ26/Bl4c7mpuS+Sqs/bLSImkpqzo6mpqf7H2U2aBOPHw5Lc1v3s\n2akbYJyfdmlWDyfvxubvZ/XojmfgW5Man58maRawJXBfblf3KVZsPH7L3K/znXnm8uRdsWRJ6m9m\nZrYK3S6BR8SDEbFJRAyNiKGkavKdI2Ie8DvgcElrSxoGbMPqatHsiSfq629mDWnhwoWMGTOGMWPG\nMGjQILbYYotl3a+//nqbpnHMMcfw6KOPtjrO+eefz6ROusx2/fXXM2bMGHbccUdGjBjBhRde2Or4\nt956K3fffXenzNs6T5evQpd0JbA3sFFuWeqrEXFRrXEj4mFJVwPTgaXASavtDvTBg1O1ea3+Zrb6\nTJqUarqeeCL93iZM6NBlqw033JCpU6cC8LWvfY3+/fvzuc99boVxIoKIoEeP2udMv/zlL1c5n5NO\nOqndMVZ77bXXOPHEE5k8eTKbb745r732GrNr7Yuq3HrrrWy00UbsuuuunRKDdY4ufwYeEUdExGYR\n0TsitmyevPOZ+LNV3RMiYuuI2C4iblhtgU2YAH37rtivb9/U38xWj8q9J7NnQ8Tye09Www2kjz32\nGCNGjGDcuHGMHDmSuXPnMn78eJqamhg5ciTf+MY3lo27xx57MHXqVJYuXcrAgQM544wz2HHHHdlt\nt9145plnAPjSl77Eueeeu2z8M844g7Fjx7Lddtvxt7/9DYCXX36ZD3/4w4wYMYJDDz2UpqamZQcX\nFYsWLSIi2GCDDQBYe+212XbbbQGYP38+hxxyCE1NTYwdO5a7776bf/3rX1x44YWcffbZjBkzZtm8\nrHhdPoE3rHHjYOJEGDIEpPQ+caJvYDNbndbwvSePPPIIp556KtOnT2eLLbbgrLPOYvLkyUybNo2b\nbrqJ6dOnr1Rm0aJFvOtd72LatGnstttuXHzxxTWnHRHce++9nH322csOBn784x8zaNAgpk+fzpe/\n/GXuv//+lcptsskm7L///gwZMoSPfexjXHnllbz11lsAnHLKKZx++ulMnjyZq6++muOPP56tt96a\n448/ntNOO42pU6fyzne+sxPXkHVEl69Cb2jjxjlhm61Ja/jek6233pqmpqZl3VdeeSUXXXQRS5cu\n5emnn2b69OmMGDFihTLrrLMOBx54IAC77LILd955Z81pH3LIIcvGmTVrFgB33XUXn//85wHYcccd\nGTlyZM2yl1xyCQ888AA333wzZ511FrfccgsXXnghN9988wrX4p9//nleeeWV9i28rXZO4GbWfazh\ne0/69eu37PPMmTP50Y9+xL333svAgQM58sgja/43eq211lr2uWfPnixdurTmtNdee+1VjtOa0aNH\nM3r0aD72sY8xfPhwLrzwwmVn9dUxWONyFbqZdR8F3nuyePFiBgwYwLrrrsvcuXP585//3Onz2H33\n3bn66qsBePDBB2tW0S9evJg77rhjWffUqVMZMmQIAPvttx/nn3/+CsMABgwYwIsvvtjp8VrHOIGb\nWfdR4L0nO++8MyNGjGD77bfn4x//OLvvvnunz+Pkk0/mqaeeYsSIEXz9619nxIgRrLfeeiuMExF8\n5zvfYbvttmPMmDF861vfWnad/fzzz+evf/0ro0ePZsSIEfziF78A4KCDDuLqq69mp5128k1sDUQR\n9T9EzFbU1NQUkydPLjoMs25pxowZDB8+vOgwGsLSpUtZunQpffr0YebMmbznPe9h5syZ9OpV/NXS\nWt+TpCkR0dRCEVuF4r9VMzPrFC+99BL77rsvS5cuJSK44IILGiJ52+rhb9bMrIsYOHAgU6ZMKToM\nW0N8DdzMzKyEnMDNzMxKyAnczMyshJzAzczMSsgJ3MysA/bZZ5+VHspy7rnncuKJJ7Zarn///gA8\n/fTTHHrooTXH2XvvvVnVX1TPPfdcllQ93/29730vL7zwQltCb9Wjjz7K3nvvzZgxYxg+fDjjx49v\ndfxZs2ZxxRVXdHi+1nZO4GbWbQwalJ7f0vw1aFD7p3nEEUdw1VVXrdDvqquu4ogjjmhT+c0335xr\nr7223fNvnsD/+Mc/MnDgwHZPr+KUU07h1FNPZerUqcyYMYOTTz651fGdwNc8J3Az6zbmz6+vf1sc\neuih/OEPf+D1118HUiJ7+umn2XPPPZf9L3vnnXdmhx124Prrr1+p/KxZsxg1ahQAr7zyCocffjjD\nhw/n4IMPXqEhkRNPPHFZU6Rf/epXATjvvPN4+umn2Weffdhnn30AGDp0KM8+m1pIPueccxg1ahSj\nRo1a1hTprFmzGD58OJ/4xCcYOXIk73nPe2o2WDJ37ly23HLLZd077LADAG+++SannXYab3/72xk9\nejQXXHABAGeccQZ33nknY8aM4Yc//GH7V6i1XaWheb/a/9pll13CzIoxffr0No+bGgGv/eqI973v\nfXHddddFRMR3vvOd+OxnPxsREW+88UYsWrQoIiIWLFgQW2+9dbz11lsREdGvX7+IiHj88cdj5MiR\nERHxgx/8II455piIiJg2bVr07Nkz/vGPf0RExMKFCyMiYunSpfGud70rpk2bFhERQ4YMiQULFiyL\npdI9efLkGDVqVLz00kvx4osvxogRI+K+++6Lxx9/PHr27Bn3339/REQcdthhcdlll620TBdffHGs\nu+66ccABB8Q555wTzz//fEREXHDBBfHNb34zIiJeffXV2GWXXeLf//533HbbbfG+972vxXVU63sC\nJkcD7MPL+vIZuJlZB1VXo1dXn0cEX/ziFxk9ejT77bcfTz31FPNbOd2/4447OPLII4HlrYVVXH31\n1ey8887stNNOPPzwwzUbKql21113cfDBB9OvXz/69+/PIYccsqxp0mHDhjFmzBhgxeZIqx1zzDHM\nmDGDww47jNtvv51dd92V1157jRtvvJFf/epXjBkzhne84x0sXLiQmTNntn1lWafxk9jMzDrooIMO\n4tRTT+W+++5jyZIl7LLLLgBMmjSJBQsWMGXKFHr37s3QoUNrNiG6Ko8//jjf//73+cc//sH666/P\n0Ucf3a7pVFSaIoXUHGlLbX5vvvnmHHvssRx77LGMGjWKhx56iIjgxz/+Mfvvv/8K495+++3tjsfa\nx2fgZmYd1L9/f/bZZx+OPfbYFW5eW7RoEZtssgm9e/fmtttuY3attsir7LXXXstuBHvooYd44IEH\ngNQEaL9+/VhvvfWYP38+N9xww7IyLTX1ueeee3LdddexZMkSXn75ZX7729+y5557tnmZ/vSnP/HG\nG28AMG/ePBYuXMgWW2zB/vvvz89+9rNlw/75z3/y8ssvu8nRAvgM3My6jU03rX3D2qabdnzaRxxx\nBAcffPAKd6SPGzeOD3zgA+ywww40NTWx/fbbtzqNE088kWOOOYbhw4czfPjwZWfyO+64IzvttBPb\nb789W2211QpNkY4fP54DDjiAzTffnNtuu21Z/5133pmjjz6asWPHAnD88cez00471awur+XGG2/k\n05/+NH369AHg7LPPZtCgQRx//PHMmjWLnXfemYhg44035rrrrmP06NH07NmTHXfckaOPPppTTz21\nTfOx9nNzop3AzYmaFcfNiZaDmxPtfK5CNzMzKyEncDMzsxIqZQKXtJ6kEUXHYWaNwZcCG5u/n9Wj\nNAlc0i2S1pW0PjAVuEzS2UXHZWbF6tOnDwsXLnSSaFARwcKFC5fdDGedp0x3oW8QEYslHQdcHhFf\nlvQAcFrRgZlZcbbcckvmzJnDggULig7FWtCnT58VHstqnaNMCbyXpI2Bw4CvFB2MmTWG3r17M2zY\nsKLDMFvjSlOFDkwA/gI8ERH3Snob8HjBMZmZmRWiNGfgEXEVcFVV97+Bg4qLyMzMrDgNn8Al/RBo\n8e6UiPjMGgzHzMysITR8AgceKjoAMzOzRtPwCTwiLqrulrR2RLxWVDxmZmaNoDQ3sUkaK+lBYGbu\n3lHSjwsOy8zMrBClSeDAecD7gYUAETEN2KfQiMzMzApSpgTeIyKaN6b7ZiGRmJmZFazhr4FXeVLS\nWCAk9QROBv5ZcExmZmaFKNMZ+InAZ4DBwHxg19zPzMys2ynNGXhEPAMcXnQcZmZmjaDhE3hHH+Qi\n6WLSzW/PRMSo3O9s4APA68C/gGMi4oU87AvAcaTr66dExJ87YznMzMw6Uxmq0B8CHgYGALsBT+bX\nO4D+bSh/CXBAs343AaMiYjTpOvoXAHIb44cDI3OZn+br7WZmZg2l4c/AKw9ykfQJYI+IWJq7zyc1\nbrKq8ndIGtqs341VnXcDh+bPBwFX5QfFPC7pMWAs8PcOLoaZmVmnKsMZeMX6rHjG3RfYoBOmeyxw\nQ/68BensvmJO7rcSSeMlTZY02e0Qm5nZmtbwZ+BVzgamSroZEOkhLt/qyAQlnQksBSbVWzYiJgIT\nAZqamlq8Rm9mZrY6lCaBR8SFkm4g/X0sgK9ExFPtnZ6ko0k3t+0bEZUE/BSwVdVoW+Z+ZmZmDaVM\nVegAOwJvJ12XHt3eiUg6ADgd+GBELKka9DvgcElrSxoGbAPc24F4zczMVovSnIFLmgDsDlyRe50m\nafeI+NIqyl0J7A1sJGkO8FXSXedrAzdJArg7Ik6IiIclXQ1MJ1WtnxQRflyrmZk1HC2vPW5skh4A\ndqokVEm9gPvyX8EK1dTUFJMnTy46DDOzUpE0JSKaio6jrMpWhb5u1ecBhUVhZmZWsNJUoQPfA+6T\ndAvpLvS9gS8XGpGZmVlBSpPAI+JySbeRnsAGHbwL3czMrMwaPoFLan6N+7H8vqGkDSPigTUdk5mZ\nWdEaPoEDU0l3hT+Xu1U1LIC91nhEZmZmBStDAj8dOAR4AbgSuL7Zf7fNzMy6nYa/Cz0ivh8R7wQ+\nS3qwyl9DzORHAAAajUlEQVQkXVGjat3MzKzbaPgEXhERM4FfA/8H7AGMKDYiMzOz4jR8FbqkwaQ2\nug8G5pGS+PCIeLnQwMzMzArU8AkcmAU8APyWdB18E+C4/AhUIuK8wiIzMzMrSBkS+LdJd5v3AjYq\nOBYzM7OG0PAJfFWNlZiZmXVHpbmJzczMzJZzAjczMyshJ3AzM7MSavhr4BWS1gWOBIZSFXdEfKao\nmMzMzIpSmgQO/BG4D3gQeKvgWMzMzApVpgTeNyJOKToIMzOzRlCma+BXSDpG0saS1q28ig7KzMys\nCGU6A38JOBf4JunBLuT3wYVFZGZmVpAyJfDPA9tExDNFB2JmZla0MlWhPwYsLjoIMzOzRlCmM/DF\nwP2SbgVeq/T038jMzKw7KlMC/2N+mZmZdXulSeARcVHRMZiZmTWK0iRwSVsDE4ARQJ9K/4jYtrCg\nzMzMClKmm9guAX4JCDgQuBr4dZEBmZmZFaVMCbxvRPwZICL+ldsJP7DgmMzMzApRmip04DVJPYB/\nSToBeAoYUHBMZmZmhShTAj8V6AecQroWvi5wbKERmZmZFaQUCVxST+DgiLgHeBH4r4JDMjMzK1Qp\nroFHxJvAPkXHYWZm1ihKcQaeTZH0G+Aa4OVKz4j4XXEhmZmZFaNMCXwAKXG/t6pfAE7gZmbW7ZQm\ngUeEr3ubmZllpUngks6p0XsRMDki/rCm4zEzMytSKW5iywYA7wCezK+3A8OA/5b0gyIDMzMzW9NK\ncwYOjAL2jIilAJJ+AtwB7AlMAz5bYGxmZmZrVJnOwDcA+lZ1rwNskBP6a7WLgKSLJT0j6aGqfhtI\nuknSzPy+ftWwL0h6TNKjkvZfHQtiZmbWUWVK4OcAUyX9QtKFwH3AOZL6Abe3Uu4S4IBm/c4AbomI\nbYBbcjeSRgCHAyNzmZ/mh8iYmZk1lNIk8Ii4ANgL+BNwA7BPRFwQES9HxGdaKXcH8Fyz3gcBl+bP\nlwIfqup/VUS8FhGPA48BYztxMczMzDpFwydwSdvk99GkavSZ+bV+7tcem0bE3Px5HrBp/rwF6Qa5\nijm5X624xkuaLGnyggUL2hmGmZlZ+5ThJrYzgOOA82sMC9JZebtFREiKdpSbCEwEaGpqqru8mZlZ\nRzR8Ao+I43IzoqdFxN2dNNn5kjaLiLmSNgOeyf2fAraqGm/L3M/MzKyhNHwVOkBEvAX8vBMn+Tvg\nqPz5KOD6qv6HS1pb0jBgG+DeTpyvmZlZpyhFAs9uk3RQvYUkXQn8HdhO0hxJxwFnAf8paSawX+4m\nIh4Grgamk26WOym3hGZmZtZQFFGOy7eSngfWI/3n+xVApEvYGxQaGOka+OTJk4sOw8ysVCRNiYim\nouMoq4a/Bi5pcEQ8AWxUdCxmZmaNogxV6NcBRMSbtV5FB2dmZlaEMiRwFR2AmZlZo2n4KnRgC0nn\ntTQwIk5Zk8GYmZk1gjIk8FeAKUUHYWZm1kjKkMAXRsSlqx7NzMys+yjDNfDXiw7AzMys0TR8Ao+I\nXYuOwczMrNE0fALvqgYNAmnl16BBRUdmZmZl4ARekPnz6+tvZmZWrRQJXFJPSY8UHYeZmVmjKEUC\nz09ce1TS4KJjMTMzawRl+BtZxfrAw5LuBV6u9IyIDxYXkpmZWTHKlMC/XHQAZmZmjaIUVegAEfEX\n4BFgQH7NyP1KadNN6+tvZmZWrTQJXNJHgHuBw4CPAPdIOrTYqNpv3jyIWPk1b14dE5k0CYYOhR49\n0vukSaspWjMzazRlqkI/E3h7RDwDIGlj4Gbg2kKjKsqkSTB+PCxZkrpnz07dAOPGFReXmZmtEaU5\nAwd6VJJ3tpByxd+5zjxzefKuWLIk9Tczsy6vTGfgf5L0Z+DK3P1R4I8FxlOsJ56or7+ZmXUppUng\nEXGapA8Du+deEyPit0XGVKjBg1O1ea3+ZmbW5TV8FbSkZY2ZRMT/RsRn8qv7Jm+ACROgb98V+/Xt\nm/qbmVmX1/AJHPhp5YOkvxcZSEMZNw4mToQhQ1IrKEOGpG7fwGZm1i2UoQpdVZ/7FBZFIxo3zgnb\nzKybKkMC7yFpfVJtQeXzsqQeEc8VFpmZmVlBypDA1wOmsDxp31c1LIC3rfGIzMzMCtbwCTwihhYd\ng5mZWaMpw01sZmZm1owTuJmZWQk5gZuZmZVQaRK4pB9IGll0HGZmZo2gNAkcmAFMlHSPpBMkrVd0\nQGZmZkUpTQKPiAsjYnfg48BQ4AFJV0jap9jIzMzM1rzSJHAAST2B7fPrWWAa8BlJVxUamJmZ2RrW\n8P8Dr5D0Q+D9wK3AtyPi3jzou5IeLS4yMzOzNa80CRx4APhSRLxcY9jYNR2MmZlZkcpUhX5k8+Qt\n6RaAiFhUTEhmZmbFaPgzcEl9gL7ARs0aMlkX2KKwwMzMzArU8Akc+CTwP8DmrNiQyWLgJ4VEZGZm\nVrCGr0KPiB9FxDDgcxExrOq1Y0R0KIFLOlXSw5IeknSlpD6SNpB0k6SZ+X39TlqUTjVoEEgrvwYN\nKjoyMzNbExo+gUt6d/74lKRDmr86MN0tgFOApogYBfQEDgfOAG6JiG2AW3J3w5k/v77+NU2aBEOH\nQo8e6X3SpE6IzMzM1oQyVKG/i/TXsQ/UGBbAbzow7V7AOpLeIF1nfxr4ArB3Hn4pcDvw+Q7MozFN\nmgTjx8OSJal79uzUDTBuXHFxmZlZmygiio6hMJI+DUwAXgFujIhxkl6IiIF5uIDnK93Nyo4HxgMM\nHjx4l9mzZ6/ByFN1eUva9JUOHZqSdnNDhsCsWe2Mysys7SRNiYimouMoq4avQq+QdFn1888lDan8\njayd01sfOAgYRrpBrp+kI6vHiXR0UzMdRsTEiGiKiKaNN964vWEU54kn6utvZmYNpTQJHLgLuEfS\neyV9ArgJOLcD09sPeDwiFkTEG6Sq+HcC8yVtBpDfn+lg3I1p8OD6+puZWUMpTQKPiAuA44HrgW8A\ne0XE7zswySeAXSX1zVXl+5JaPPsdcFQe56g8v4az6ab19V/JhAnQt++K/fr2Tf3NzKzhlSaBS/ov\n4GJSa2SXAH+UtGN7pxcR9wDXkv5b/iBpXUwEzgL+U9JM0ln6WR2LfPWYNy9d627+mjevjRMYNw4m\nTkzXvKX0PnGib2AzMyuJ0tzEJuk6YHxEPJO7xwITI2JMsZFBU1NTTJ48uegwzMxKxTexdUwZ/kYG\nQER8qFn3vTmJm5mZdTtlqkLfVtItkh7K3aOB0wsOy8zMrBClSeDAL0gPWXkDICIeID05zczMrNsp\nUwLvGxH3Nuu3tJBIugA/S93MrNzKlMCflbQ1+cEqkg4F5hYbUnl1yrPUzcysMGVK4CcBFwDbS3qK\n1MToicWG1M25MRQzs8KU6S70fwP7SeoH9IiIF4uOqVtzYyhmZoVq+P+BS/pMa8Mj4pw1FUtLyvg/\ncDeGYmZF8//AO6YMZ+ADig7AanBjKGZmhWr4BB4RXy86hq5o001r37DW5mepDx5c+wzcjaGYma0R\npbmJTdLbJP1e0gJJz0i6XtLbio6rrDr6LPVBL8xAxEqvQS/MWL2Bm5kZUKIEDlwBXA1sRmq/+xrg\nykIj6sbmL1qnrv5mZta5ypTA+0bEZRGxNL8uB/oUHZSZmVkRGv4aeJUbJJ0BXEV6mMtHSU2KbgAQ\nEc8VGZyZmdmaVKYE/pH8/slm/Q8nJXRfDy+RQYNavomuzW2am5l1Y6VI4JJ6AEdGxF+LjsU6hx/l\nambWMaW4Bh4RbwE/KToOW66lv5u1+W9oZmbWIaVI4Nktkj4stfYMMVtTOvo3tI5ya2pm1t2VKYF/\nkvTXsdclLZb0oqTFRQdlxXAVvJl1d6VJ4BExICJ6RETviFg3d69bdFxWTj6DN7OyK00CV3KkpC/n\n7q0kjS06Lmufoq+h+wzezMquNAkc+CmwG/Cx3P0ScH5x4VhHFH0NvSN89m5mjaBMCfwdEXES8CpA\nRDwPrFVsSNYddfTs3QcAZtYZypTA35DUk/TQFiRtDLxVbEhWlE17LKirfyMp+gDABxBmXUOZEvh5\nwG+BTSRNAO4Cvl1sSFaUebFpjbbQxLzo+n9E7+gBgA8gzLqG0iTwiJgEnA58B5gLfCgirik2KitM\nS+2Ot7E98qJvoiuz7n4A4fI+AGsUDZ/AJfWR9D+SfgK8C7ggIn4SEW54ujubMAH69l2xX9++qX8b\nzJsHcfkkYshQQj3S++WTSnETXXdX9AGEy3esvHWehk/gwKVAE/AgcCDw/WLDsYYwbhxMnAhDhqTD\n/yFDUve4cW0rP2kSjB8Ps2en299nz07dkyatsqjP3s2sESgiio6hVZIejIgd8udewL0RsXPBYa2g\nqakpJk+eXHQYVo+hQ1PSbm7IEJg1a7XOuqMtsbX2MOG2/Jxd3uWLLL/itDQlIprqK2UVZTgDf6Py\nISKWFhmIdSFPPFFf/07U0f/Ad7QGwDUIZl1DGRL4jvnZ54slvQiM9rPQrcM6eBMckyals/gePdJ7\nG6reO0tHDwB8AGHWNTR8Ao+InvnZ55Xnn/fys9CtwzpyE1wHrp93Bd39AMLlO1beOk/DXwMvA18D\nL6lJk+DMM1O1+eDBKXm35Sa4Aq+fm3UlvgbeMQ1/Bm622owblxLuW2+l97bewd4Z188LrII3s67B\nCdysXp1x/bwbV8GbWedwAjerVwcfIsOZZ8KSJSv2W7Ik9TczayMncLN6dfQhMq6CN7NO0KvoAMxK\nady4tifs5gYPrn0TXL1V8JWz+EoVfCUuM+sWuvUZuKSBkq6V9IikGZJ2k7SBpJskzczv6xcdp3Ux\njVAF7zN4s9Lr1gkc+BHwp4jYHtgRmAGcAdwSEdsAt+Rus85TdBW8b6Iz6xK6bQKXtB6wF3ARQES8\nHhEvAAeRGlAhv3+omAitS2vvX9ig43fB+wzerEvotgkcGAYsAH4p6X5JF0rqB2waEXPzOPOAms8X\nkjRe0mRJkxcsWLCGQjaj41XwPoM36xK6cwLvBewM/CwidgJepll1eaTH1NV8VF1ETIyIpoho2njj\njVd7sGbLdLQK3mfwZl1Cd07gc4A5EXFP7r6WlNDnS9oMIL8/U1B8Zi3rSBW8z+DNuoRum8AjYh7w\npKTtcq99genA74Cjcr+jgOsLCM9s9fEZvFmX0G0TeHYyMEnSA8AY4NvAWcB/SpoJ7Je7zbqW7n4G\n7wMA6wLcGlkncGtk1u20tyU36Hhrbh0t3/xBOJAOQOqphbBO4dbIOqa7n4GbWXuU+QzeVfjWRTiB\nm9maVfQ1eFfhWxfhBG5ma16RZ/BF34TnAwDrJE7gZlYuHT2DL3sVvg8ALHMCN7Py6cgZfNmr8H0A\nYJnvQu8EvgvdrBvp6F3sHb2LvkePlHibk9IBzeqefyfexe+70DvGZ+BmZvUougq/7DUA1mmcwM3M\n6lVkFX7ZDwCs0ziBm5mtad35AMA6jRO4mVnZlPkAwDpNr6IDMDOzNWzcuPY/NrZSrr2P0rVO4wRu\nZmb16cgBgHUaV6GbmZmVkBO4mZlZCTmBm5mZlZATuJmZWQk5gZuZmZWQn4XeCSS9CDzagUlsBDzr\n8qUsX+bYXd7liy6/XUQM6ED5bs1/I+scj3bkgfySJrt8OcuXOXaXd/lGKN/esuYqdDMzs1JyAjcz\nMyshJ/DOMdHlu235Msfu8i5f9vLdmm9iMzMzKyGfgZuZmZWQE7iZmVkJOYF3EkmHSXpY0luS2vS3\nCkkHSHpU0mOSzmjHPC+W9Iykh9pRditJt0manuP+dJ3l+0i6V9K0XP7r9caQp9NT0v2S/q8dZWdJ\nelDS1Pb8HUXSQEnXSnpE0gxJu9VRdrs838prsaT/qXP+p+Z195CkKyX1qbP8p3PZh9sy71rbi6QN\nJN0kaWZ+X7/O8m3e7lsof3Ze/w9I+q2kgXWW/2YuO1XSjZI2r6d81bDPSgpJG9U5/69JeqpqO3hv\nvfOXdHJeBw9L+l6d8/911bxnSZpaZ/kxku6u/IYkja2z/I6S/p5/h7+XtG4LZWvub+rZ/qyGiPCr\nE17AcGA74HagqQ3j9wT+BbwNWAuYBoyoc557ATsDD7Uj3s2AnfPnAcA/65k/IKB//twbuAfYtR1x\nfAa4Avi/dpSdBWzUge/sUuD4/HktYGA7p9MTmAcMqaPMFsDjwDq5+2rg6DrKjwIeAvqSnudwM/Af\n9W4vwPeAM/LnM4Dv1lm+zdt9C+XfA/TKn7/bjvmvW/X5FODn9ZTP/bcC/gzMbm17amH+XwM+18bv\nrFb5ffJ3t3bu3qTe+KuG/wD4Sp3zvxE4MH9+L3B7neX/Abwrfz4W+GYLZWvub+rZ/vxa+eUz8E4S\nETMiop6nsY0FHouIf0fE68BVwEF1zvMO4Ll6ylSVnRsR9+XPLwIzSEmlreUjIl7Knb3zq647IiVt\nCbwPuLCecp1B0nqkHdJFABHxekS80M7J7Qv8KyJm11muF7COpF6kRPx0HWWHA/dExJKIWAr8BTik\ntQItbC8HkQ5kyO8fqqd8Pdt9C+VvzPED3A1sWWf5xVWd/WhlG2zl9/JD4PTWyq6ifJu0UP5E4KyI\neC2P80x75i9JwEeAK+ssH0DlrHk9WtkGWyi/LXBH/nwT8OEWyra0v2nz9mcrcwIvzhbAk1Xdc6gj\ngXYmSUOBnUhn0fWU65mr7J4BboqIusoD55J2nG/VWa4igJslTZE0vs6yw4AFwC9zFf6Fkvq1M47D\naWXHWUtEPAV8H3gCmAssiogb65jEQ8CekjaU1Jd09rRVPTFkm0bE3Px5HrBpO6bRWY4Fbqi3kKQJ\nkp4ExgFfqbPsQcBTETGt3vlWOTlX41/cjirgbUnf4z2S/iLp7e2MYU9gfkTMrLPc/wBn5/X3feAL\ndZZ/mOUnHofRhm2w2f6mkba/0nECr4Okm/M1x+avus6cG4mk/sD/Av/T7GxmlSLizYgYQzprGitp\nVB3zfT/wTERMqSvgFe2R538gcJKkveoo24tUHfiziNgJeJlUhVcXSWsBHwSuqbPc+qQd3zBgc6Cf\npCPbWj4iZpCqnG8E/gRMBd6sJ4Ya0wzqrEXpLJLOBJYCk+otGxFnRsRWueyn6phnX+CL1Jn0m/kZ\n6TLYGNKB2A/qLN8L2ADYFTgNuDqfTdfrCOo8iMxOBE7N6+9Uco1UHY4F/lvSFFLV+Outjdza/qbI\n7a+snMDrEBH7RcSoGq/r2zG5p1jxaHXL3G+NkdSb9GOaFBG/ae90ctXzbcABdRTbHfigpFmkywfv\nlnR5nfN9Kr8/A/yWdFmireYAc6pqDa4lJfR6HQjcFxHz6yy3H/B4RCyIiDeA3wDvrGcCEXFRROwS\nEXsBz5OuK9ZrvqTNAPJ7i1W4q4uko4H3A+PyTry9JtFCFW4LtiYdQE3L2+GWwH2SBrV1AhExPx/I\nvgX8gvq2QUjb4W/yJal7SbVRLd5IV0u+BHMI8Os65w1wFGnbg3QQWlf8EfFIRLwnInYhHUD8q5U4\na+1vCt/+yswJvDj/ALaRNCyfxR0O/G5NzTwf5V8EzIiIc9pRfmPlO4YlrQP8J/BIW8tHxBciYsuI\nGEpa9lsjos1noJL6SRpQ+Uy6GarNd+NHxDzgSUnb5V77AtPbWr5Ke898ngB2ldQ3fxf7kq4Ltpmk\nTfL7YNIO/Ip2xPE70k6c/N6eg9F2k3QA6TLKByNiSTvKb1PVeRD1bYMPRsQmETE0b4dzSDdazatj\n/ptVdR5MHdtgdh3pRjYkbUu6mbLe1r32Ax6JiDl1loN0zftd+fO7gbqq4Ku2wR7Al4CftzBeS/ub\nQre/0lsdd8Z1xxfpxzsHeA2YD/y5DWXeSzpr+hdwZjvmeSWp2u6NPO/j6ii7B6m66gFS9etU4L11\nlB8N3J/LP0Qrd7+2YVp7U+dd6KRqy2n59XA7198YYHJehuuA9ess3w9YCKzXzuX+OinhPARcRr4T\nuY7yd5IOOqYB+7ZnewE2BG4h7bhvBjaos3ybt/sWyj9Guheksg22dhd5rfL/m9ffA8DvgS3a+3th\nFf9qaGH+lwEP5vn/DtiszvJrAZfnZbgPeHe98QOXACe08/vfA5iSt6F7gF3qLP9p0j7sn8BZ5Kd7\n1ihbc39Tz/bn18ovP0rVzMyshFyFbmZmVkJO4GZmZiXkBG5mZlZCTuBmZmYl5ARuZmZWQk7gZp1M\n0ptasaWyup/w1sq0h6oNrc8ptZK1pPI/3dzvpdbKdHYMZrZ69So6ALMu6JVIj3gt2rPAZ4HPFx1I\nNUm9YnkDJmbWTj4DN1tDcnvN38ttJ98r6T9y/6GSbs0NYtySn6yGpE2V2siell+VR632lPSL3K7y\njflJeLVcDHxU0gbN4ljhDFrS5yR9LX++XdIPldqGniHp7ZJ+o9Re87eqJtNL0qQ8zrX5ueJI2iU3\nyjFF0p+rHpN5u6Rzldptr6vteTOrzQncrPOt06wK/aNVwxZFxA7AT0itsQH8GLg0IkaTnud9Xu5/\nHvCXiNiR9Jz2h3P/bYDzI2Ik8AItP//7JVISrzdhvh4RTaTHYl4PnERqf/xoSRvmcbYDfhoRw4HF\npAYteudlOTTSs7EvBiZUTXetiGiKiHob/DCzGlyFbtb5WqtCv7Lq/Yf5824sb8v7MuB7+fO7gY9D\navkNWJRbMXs8IqbmcaYAQ1uJ5TxgqqTv1xF/5Zn8DwIPR27uUdK/SQ3wvAA8GRF/zeNdDpxCahVt\nFHBTblCrJ+nRmxXtaWzDzFrgBG62ZkULn+vxWtXnN4GWqtCJiBckXUE6i65Yyoq1b31amP5bzeb1\nFsv3Gc1jD0CkhL9bC+G83FKcZlY/V6GbrVkfrXr/e/78N1KLbADjSI2UQGrk4UQAST0lrdfOeZ4D\nfJLlyXc+sImkDSWtTWrKs16DJVUS9ceAu4BHgY0r/SX1ljSynTGb2So4gZt1vubXwM+qGra+pAdI\n16VPzf1OBo7J/f+L5desPw3sI+lBUlX5iPYEExHPktpLXzt3vwF8A7gXuIk6muCs8ihwkqQZwPrA\nzyLideBQ4LuSppFanKqrjXMzazu3Rma2hkiaBTTlhGpm1iE+AzczMyshn4GbmZmVkM/AzczMSsgJ\n3MzMrIScwM3MzErICdzMzKyEnMDNzMxK6P8BojPWtyZTgLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137d31f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the perplexities of training/validation trigram models using labeled + unlabeled data \n",
    "plt.plot(train_perplexity_all_trigram, 'ro', label='Training Set')\n",
    "plt.plot(valid_perplexity_all_trigram, 'bs', label='Validation Set')\n",
    "plt.title('Training vs. Validation Perplexity On Trigram Models With Extra Unlabeled Data')\n",
    "plt.ylabel('Perplexity For Trigram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEWCAYAAAAgpUMxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCi+AnHPOFYUXQM4554rCCyDnnHNF8f8BSW3xz+MbYXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1392761d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the validation perplexities with and without the extra unlabeled data\n",
    "plt.plot(valid_perplexity_labeled_trigram, 'ro', label='Only Labeled Data')\n",
    "plt.plot(valid_perplexity_all_trigram, 'bs', label='Use Extra Unlabeled Data')\n",
    "plt.title('Comparison Between Validation Perplexities On Trigram Models ')\n",
    "plt.ylabel('Perplexity For Trigram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 27.8s. Train perplexity:  163.714 Valid perplexity:  102.858\n",
      "Epoch   1 took 26.0s. Train perplexity:   99.259 Valid perplexity:   86.722\n",
      "Epoch   2 took 28.0s. Train perplexity:   86.665 Valid perplexity:   79.632\n",
      "Epoch   3 took 26.5s. Train perplexity:   79.397 Valid perplexity:   75.109\n",
      "Epoch   4 took 27.9s. Train perplexity:   73.856 Valid perplexity:   71.400\n",
      "Epoch   5 took 28.3s. Train perplexity:   69.334 Valid perplexity:   68.872\n",
      "Epoch   6 took 27.4s. Train perplexity:   65.925 Valid perplexity:   67.125\n",
      "Epoch   7 took 27.8s. Train perplexity:   63.127 Valid perplexity:   65.766\n",
      "Epoch   8 took 28.7s. Train perplexity:   60.727 Valid perplexity:   64.712\n",
      "Epoch   9 took 27.5s. Train perplexity:   58.626 Valid perplexity:   63.925\n",
      "Epoch  10 took 27.8s. Train perplexity:   56.779 Valid perplexity:   63.354\n",
      "Epoch  11 took 29.4s. Train perplexity:   55.131 Valid perplexity:   62.932\n",
      "Epoch  12 took 28.4s. Train perplexity:   53.639 Valid perplexity:   62.629\n",
      "Epoch  13 took 26.5s. Train perplexity:   52.280 Valid perplexity:   62.432\n",
      "Epoch  14 took 28.3s. Train perplexity:   51.034 Valid perplexity:   62.323\n",
      "Epoch  15 took 28.2s. Train perplexity:   49.887 Valid perplexity:   62.286\n",
      "Epoch  16 took 29.0s. Train perplexity:   48.829 Valid perplexity:   62.309\n",
      "Epoch  17 took 26.3s. Train perplexity:   47.849 Valid perplexity:   62.381\n",
      "Epoch  18 took 26.3s. Train perplexity:   46.939 Valid perplexity:   62.495\n",
      "Epoch  19 took 26.7s. Train perplexity:   46.090 Valid perplexity:   62.644\n",
      "Saving embeddings to embeds_baseline_lm_4gram\n"
     ]
    }
   ],
   "source": [
    "# Task 6 4-grams\n",
    "\n",
    "USE_UNLABELED = False\n",
    "train_perplexity_labeled_4gram = []\n",
    "valid_perplexity_labeled_4gram = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "    if USE_UNLABELED:\n",
    "        #__FIXME__\n",
    "        with open(os.path.join('processed', 'unlab_ix.pkl'), 'rb') as f:\n",
    "            train_ix += pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    lm = SimpleNLM(4, params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, batch_size=BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, batch_size=BATCH_SIZE)\n",
    "\n",
    "    n_train_words = sum(len(sent) for _, sent in train_ix)\n",
    "    n_valid_words = sum(len(sent) for _, sent in valid_ix)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate loss.\n",
    "        valid_loss = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=False)\n",
    "            valid_loss += loss.value()\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train perplexity: {:8.3f} \"\n",
    "               \"Valid perplexity: {:8.3f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            exp(total_loss / n_train_words),\n",
    "            exp(valid_loss / n_valid_words)\n",
    "            ))\n",
    "        train_perplexity_labeled_4gram.append(exp(total_loss / n_train_words))\n",
    "        valid_perplexity_labeled_4gram.append(exp(valid_loss / n_valid_words))\n",
    "        \n",
    "    # FIXME: make sure to update filenames when implementing ngram models\n",
    "    fn = \"embeds_baseline_lm_4gram\"\n",
    "    if USE_UNLABELED:\n",
    "        fn += \"_unlabeled\"\n",
    "\n",
    "    print(\"Saving embeddings to {}\".format(fn))\n",
    "    lm.embed.save(fn, \"/embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 49.0s. Train perplexity:  115.832 Valid perplexity:   80.752\n",
      "Epoch   1 took 49.0s. Train perplexity:   77.937 Valid perplexity:   68.967\n",
      "Epoch   2 took 47.8s. Train perplexity:   68.484 Valid perplexity:   63.867\n",
      "Epoch   3 took 44.5s. Train perplexity:   63.202 Valid perplexity:   60.799\n",
      "Epoch   4 took 48.3s. Train perplexity:   59.610 Valid perplexity:   58.883\n",
      "Epoch   5 took 46.5s. Train perplexity:   57.048 Valid perplexity:   57.594\n",
      "Epoch   6 took 46.8s. Train perplexity:   55.079 Valid perplexity:   56.684\n",
      "Epoch   7 took 46.9s. Train perplexity:   53.487 Valid perplexity:   56.011\n",
      "Epoch   8 took 46.5s. Train perplexity:   52.146 Valid perplexity:   55.509\n",
      "Epoch   9 took 48.3s. Train perplexity:   50.978 Valid perplexity:   55.118\n",
      "Epoch  10 took 48.0s. Train perplexity:   49.952 Valid perplexity:   54.783\n",
      "Epoch  11 took 47.2s. Train perplexity:   49.073 Valid perplexity:   54.535\n",
      "Epoch  12 took 47.8s. Train perplexity:   48.312 Valid perplexity:   54.358\n",
      "Epoch  13 took 47.3s. Train perplexity:   47.635 Valid perplexity:   54.225\n",
      "Epoch  14 took 46.4s. Train perplexity:   47.024 Valid perplexity:   54.125\n",
      "Epoch  15 took 46.6s. Train perplexity:   46.471 Valid perplexity:   54.052\n",
      "Epoch  16 took 46.7s. Train perplexity:   45.968 Valid perplexity:   53.999\n",
      "Epoch  17 took 46.7s. Train perplexity:   45.511 Valid perplexity:   53.964\n",
      "Epoch  18 took 44.4s. Train perplexity:   45.094 Valid perplexity:   53.946\n",
      "Epoch  19 took 45.7s. Train perplexity:   44.715 Valid perplexity:   53.943\n",
      "Saving embeddings to embeds_baseline_lm_4gram_unlabeled\n"
     ]
    }
   ],
   "source": [
    "# Task 6 trigrams with unlabeled\n",
    "\n",
    "USE_UNLABELED = True\n",
    "train_perplexity_all_4gram = []\n",
    "valid_perplexity_all_4gram = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "    if USE_UNLABELED:\n",
    "        #__FIXME__\n",
    "        with open(os.path.join('processed', 'unlab_ix.pkl'), 'rb') as f:\n",
    "            train_ix += pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    lm = SimpleNLM(4, params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, batch_size=BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, batch_size=BATCH_SIZE)\n",
    "\n",
    "    n_train_words = sum(len(sent) for _, sent in train_ix)\n",
    "    n_valid_words = sum(len(sent) for _, sent in valid_ix)\n",
    "\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate loss.\n",
    "        valid_loss = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = lm.batch_loss(batch, train=False)\n",
    "            valid_loss += loss.value()\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train perplexity: {:8.3f} \"\n",
    "               \"Valid perplexity: {:8.3f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            exp(total_loss / n_train_words),\n",
    "            exp(valid_loss / n_valid_words)\n",
    "            ))\n",
    "        train_perplexity_all_4gram.append(exp(total_loss / n_train_words))\n",
    "        valid_perplexity_all_4gram.append(exp(valid_loss / n_valid_words))\n",
    "        \n",
    "    # FIXME: make sure to update filenames when implementing ngram models\n",
    "    fn = \"embeds_baseline_lm_4gram\"\n",
    "    if USE_UNLABELED:\n",
    "        fn += \"_unlabeled\"\n",
    "\n",
    "    print(\"Saving embeddings to {}\".format(fn))\n",
    "    lm.embed.save(fn, \"/embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAEWCAYAAAAuDD1eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1392b9d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 6 4-gram Model\n",
    "# Compare the perplexities of training/validation trigram models using only labeled data \n",
    "plt.plot(train_perplexity_labeled_4gram, 'ro', label='Training Set')\n",
    "plt.plot(valid_perplexity_labeled_4gram, 'bs', label='Validation Set')\n",
    "plt.title('Training vs. Validation Perplexity On 4-gram Models With Only Labeled Data')\n",
    "plt.ylabel('Perplexity For 4-gram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAEWCAYAAACkI6QfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x139298b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the perplexities of training/validation 4-gram models using labeled + unlabeled data \n",
    "plt.plot(train_perplexity_all_4gram, 'ro', label='Training Set')\n",
    "plt.plot(valid_perplexity_all_4gram, 'bs', label='Validation Set')\n",
    "plt.title('Training vs. Validation Perplexity On 4-gram Models With Extra Unlabeled Data')\n",
    "plt.ylabel('Perplexity For 4-gram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x139fa3d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare the validation perplexities with and without the extra unlabeled data\n",
    "plt.plot(valid_perplexity_labeled_4gram, 'ro', label='Only Labeled Data')\n",
    "plt.plot(valid_perplexity_all_4gram, 'bs', label='Use Extra Unlabeled Data')\n",
    "plt.title('Comparison Between Validation Perplexities On 4-gram Models ')\n",
    "plt.ylabel('Perplexity For 4-gram Models')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend()\n",
    "plt.xticks(range(-1, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 2.1s. Train loss:  0.68899 Valid accuracy:    56.46\n",
      "Update parameters\n",
      "Epoch   1 took 2.3s. Train loss:  0.67866 Valid accuracy:    57.22\n",
      "Update parameters\n",
      "Epoch   2 took 2.0s. Train loss:  0.67112 Valid accuracy:    58.58\n",
      "Update parameters\n",
      "Epoch   3 took 2.0s. Train loss:  0.65927 Valid accuracy:    59.23\n",
      "Update parameters\n",
      "Epoch   4 took 2.3s. Train loss:  0.64471 Valid accuracy:    59.85\n",
      "Update parameters\n",
      "Epoch   5 took 1.9s. Train loss:  0.63040 Valid accuracy:    60.13\n",
      "Update parameters\n",
      "Epoch   6 took 1.8s. Train loss:  0.61786 Valid accuracy:    60.52\n",
      "Update parameters\n",
      "Epoch   7 took 1.9s. Train loss:  0.59933 Valid accuracy:    60.67\n",
      "Update parameters\n",
      "Epoch   8 took 2.1s. Train loss:  0.59194 Valid accuracy:    61.05\n",
      "Update parameters\n",
      "Epoch   9 took 1.8s. Train loss:  0.58187 Valid accuracy:    60.75\n",
      "Epoch  10 took 2.4s. Train loss:  0.56524 Valid accuracy:    60.97\n",
      "Epoch  11 took 2.2s. Train loss:  0.55450 Valid accuracy:    60.59\n",
      "Epoch  12 took 2.0s. Train loss:  0.54145 Valid accuracy:    61.11\n",
      "Update parameters\n",
      "Epoch  13 took 2.0s. Train loss:  0.53701 Valid accuracy:    61.16\n",
      "Update parameters\n",
      "Epoch  14 took 2.1s. Train loss:  0.52558 Valid accuracy:    60.77\n",
      "Epoch  15 took 2.3s. Train loss:  0.52015 Valid accuracy:    60.79\n",
      "Epoch  16 took 2.0s. Train loss:  0.51267 Valid accuracy:    61.14\n",
      "Epoch  17 took 2.3s. Train loss:  0.50486 Valid accuracy:    60.66\n",
      "Epoch  18 took 2.4s. Train loss:  0.49433 Valid accuracy:    60.66\n",
      "Epoch  19 took 2.1s. Train loss:  0.49088 Valid accuracy:    60.67\n",
      "Running model on test set. Test accuracy:    59.48\n"
     ]
    }
   ],
   "source": [
    "# Task 7 bigram embedding\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "    clf.embed.populate('embeds_baseline_lm', '/embed')\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 2.1s. Train loss:  0.69231 Valid accuracy:    56.08\n",
      "Update parameters\n",
      "Epoch   1 took 2.2s. Train loss:  0.68133 Valid accuracy:    57.48\n",
      "Update parameters\n",
      "Epoch   2 took 2.1s. Train loss:  0.67557 Valid accuracy:    58.16\n",
      "Update parameters\n",
      "Epoch   3 took 2.1s. Train loss:  0.66312 Valid accuracy:    59.08\n",
      "Update parameters\n",
      "Epoch   4 took 2.4s. Train loss:  0.65330 Valid accuracy:    59.67\n",
      "Update parameters\n",
      "Epoch   5 took 2.2s. Train loss:  0.64238 Valid accuracy:    59.98\n",
      "Update parameters\n",
      "Epoch   6 took 1.9s. Train loss:  0.63270 Valid accuracy:    60.27\n",
      "Update parameters\n",
      "Epoch   7 took 2.0s. Train loss:  0.61879 Valid accuracy:    60.68\n",
      "Update parameters\n",
      "Epoch   8 took 2.0s. Train loss:  0.60511 Valid accuracy:    60.46\n",
      "Epoch   9 took 1.9s. Train loss:  0.59230 Valid accuracy:    60.25\n",
      "Epoch  10 took 2.0s. Train loss:  0.57991 Valid accuracy:    60.39\n",
      "Epoch  11 took 2.1s. Train loss:  0.56963 Valid accuracy:    60.55\n",
      "Epoch  12 took 2.2s. Train loss:  0.55948 Valid accuracy:    60.81\n",
      "Update parameters\n",
      "Epoch  13 took 2.3s. Train loss:  0.55533 Valid accuracy:    60.97\n",
      "Update parameters\n",
      "Epoch  14 took 2.3s. Train loss:  0.54062 Valid accuracy:    60.91\n",
      "Epoch  15 took 2.2s. Train loss:  0.53409 Valid accuracy:    60.41\n",
      "Epoch  16 took 2.2s. Train loss:  0.52888 Valid accuracy:    60.77\n",
      "Epoch  17 took 2.1s. Train loss:  0.51909 Valid accuracy:    60.78\n",
      "Epoch  18 took 2.0s. Train loss:  0.50950 Valid accuracy:    60.54\n",
      "Epoch  19 took 2.2s. Train loss:  0.49854 Valid accuracy:    60.61\n",
      "Running model on test set. Test accuracy:    59.21\n"
     ]
    }
   ],
   "source": [
    "# Task 7 bigram embedding with unlabeled data\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "    clf.embed.populate('embeds_baseline_lm_unlabeled', '/embed')\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 1.9s. Train loss:  0.69132 Valid accuracy:    56.49\n",
      "Update parameters\n",
      "Epoch   1 took 2.3s. Train loss:  0.67760 Valid accuracy:    57.43\n",
      "Update parameters\n",
      "Epoch   2 took 2.2s. Train loss:  0.66591 Valid accuracy:    58.62\n",
      "Update parameters\n",
      "Epoch   3 took 1.9s. Train loss:  0.65026 Valid accuracy:    59.20\n",
      "Update parameters\n",
      "Epoch   4 took 2.3s. Train loss:  0.63536 Valid accuracy:    59.89\n",
      "Update parameters\n",
      "Epoch   5 took 1.9s. Train loss:  0.62346 Valid accuracy:    60.11\n",
      "Update parameters\n",
      "Epoch   6 took 2.0s. Train loss:  0.60871 Valid accuracy:    60.29\n",
      "Update parameters\n",
      "Epoch   7 took 2.2s. Train loss:  0.59724 Valid accuracy:    60.52\n",
      "Update parameters\n",
      "Epoch   8 took 2.3s. Train loss:  0.58564 Valid accuracy:    60.73\n",
      "Update parameters\n",
      "Epoch   9 took 1.8s. Train loss:  0.57325 Valid accuracy:    60.64\n",
      "Epoch  10 took 2.1s. Train loss:  0.56089 Valid accuracy:    60.67\n",
      "Epoch  11 took 2.2s. Train loss:  0.55013 Valid accuracy:    60.62\n",
      "Epoch  12 took 2.0s. Train loss:  0.54747 Valid accuracy:    60.77\n",
      "Update parameters\n",
      "Epoch  13 took 2.1s. Train loss:  0.53032 Valid accuracy:    60.59\n",
      "Epoch  14 took 2.2s. Train loss:  0.52327 Valid accuracy:    60.67\n",
      "Epoch  15 took 2.2s. Train loss:  0.51265 Valid accuracy:    60.63\n",
      "Epoch  16 took 2.2s. Train loss:  0.50492 Valid accuracy:    60.40\n",
      "Epoch  17 took 2.2s. Train loss:  0.50420 Valid accuracy:    60.35\n",
      "Epoch  18 took 2.0s. Train loss:  0.49325 Valid accuracy:    60.67\n",
      "Epoch  19 took 1.9s. Train loss:  0.48876 Valid accuracy:    60.37\n",
      "Running model on test set. Test accuracy:    59.47\n"
     ]
    }
   ],
   "source": [
    "# Task 7 trigram embedding\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "    clf.embed.populate('embeds_baseline_lm_trigram', '/embed')\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 2.2s. Train loss:  0.69534 Valid accuracy:    56.86\n",
      "Update parameters\n",
      "Epoch   1 took 2.2s. Train loss:  0.67763 Valid accuracy:    57.78\n",
      "Update parameters\n",
      "Epoch   2 took 2.0s. Train loss:  0.66758 Valid accuracy:    58.72\n",
      "Update parameters\n",
      "Epoch   3 took 2.0s. Train loss:  0.65662 Valid accuracy:    59.58\n",
      "Update parameters\n",
      "Epoch   4 took 2.2s. Train loss:  0.64254 Valid accuracy:    59.70\n",
      "Update parameters\n",
      "Epoch   5 took 2.1s. Train loss:  0.62767 Valid accuracy:    60.23\n",
      "Update parameters\n",
      "Epoch   6 took 2.1s. Train loss:  0.61622 Valid accuracy:    60.48\n",
      "Update parameters\n",
      "Epoch   7 took 2.3s. Train loss:  0.59955 Valid accuracy:    60.46\n",
      "Epoch   8 took 2.2s. Train loss:  0.59491 Valid accuracy:    60.56\n",
      "Update parameters\n",
      "Epoch   9 took 1.9s. Train loss:  0.57715 Valid accuracy:    60.74\n",
      "Update parameters\n",
      "Epoch  10 took 2.3s. Train loss:  0.56597 Valid accuracy:    60.77\n",
      "Update parameters\n",
      "Epoch  11 took 2.2s. Train loss:  0.55669 Valid accuracy:    60.84\n",
      "Update parameters\n",
      "Epoch  12 took 2.1s. Train loss:  0.54709 Valid accuracy:    60.58\n",
      "Epoch  13 took 2.1s. Train loss:  0.53395 Valid accuracy:    60.67\n",
      "Epoch  14 took 2.2s. Train loss:  0.53398 Valid accuracy:    60.77\n",
      "Epoch  15 took 2.0s. Train loss:  0.52180 Valid accuracy:    60.45\n",
      "Epoch  16 took 2.2s. Train loss:  0.50683 Valid accuracy:    60.82\n",
      "Epoch  17 took 2.2s. Train loss:  0.50064 Valid accuracy:    61.15\n",
      "Update parameters\n",
      "Epoch  18 took 2.0s. Train loss:  0.50486 Valid accuracy:    60.97\n",
      "Epoch  19 took 2.1s. Train loss:  0.49189 Valid accuracy:    60.36\n",
      "Running model on test set. Test accuracy:    59.44\n"
     ]
    }
   ],
   "source": [
    "# Task 7 trigram embedding with unlabeled data (best embeddings by validation set?)\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "    clf.embed.populate('embeds_baseline_lm_trigram_unlabeled', '/embed')\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 2.0s. Train loss:  0.69070 Valid accuracy:    56.67\n",
      "Update parameters\n",
      "Epoch   1 took 2.1s. Train loss:  0.67834 Valid accuracy:    57.98\n",
      "Update parameters\n",
      "Epoch   2 took 2.2s. Train loss:  0.66457 Valid accuracy:    59.01\n",
      "Update parameters\n",
      "Epoch   3 took 2.2s. Train loss:  0.64902 Valid accuracy:    59.75\n",
      "Update parameters\n",
      "Epoch   4 took 2.2s. Train loss:  0.63394 Valid accuracy:    59.83\n",
      "Update parameters\n",
      "Epoch   5 took 2.2s. Train loss:  0.62064 Valid accuracy:    60.17\n",
      "Update parameters\n",
      "Epoch   6 took 2.2s. Train loss:  0.60835 Valid accuracy:    60.29\n",
      "Update parameters\n",
      "Epoch   7 took 2.1s. Train loss:  0.59309 Valid accuracy:    60.36\n",
      "Update parameters\n",
      "Epoch   8 took 2.0s. Train loss:  0.57988 Valid accuracy:    60.56\n",
      "Update parameters\n",
      "Epoch   9 took 2.1s. Train loss:  0.56776 Valid accuracy:    60.76\n",
      "Update parameters\n",
      "Epoch  10 took 2.1s. Train loss:  0.55464 Valid accuracy:    60.71\n",
      "Epoch  11 took 1.8s. Train loss:  0.54639 Valid accuracy:    60.83\n",
      "Update parameters\n",
      "Epoch  12 took 2.0s. Train loss:  0.54046 Valid accuracy:    60.83\n",
      "Update parameters\n",
      "Epoch  13 took 2.0s. Train loss:  0.52741 Valid accuracy:    60.77\n",
      "Epoch  14 took 2.0s. Train loss:  0.51725 Valid accuracy:    60.91\n",
      "Update parameters\n",
      "Epoch  15 took 2.2s. Train loss:  0.51269 Valid accuracy:    60.38\n",
      "Epoch  16 took 2.3s. Train loss:  0.50838 Valid accuracy:    60.55\n",
      "Epoch  17 took 2.3s. Train loss:  0.49844 Valid accuracy:    60.49\n",
      "Epoch  18 took 2.0s. Train loss:  0.49462 Valid accuracy:    60.49\n",
      "Epoch  19 took 1.9s. Train loss:  0.48923 Valid accuracy:    60.21\n",
      "Running model on test set. Test accuracy:    59.29\n"
     ]
    }
   ],
   "source": [
    "# Task 7 4-gram embedding\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "    clf.embed.populate('embeds_baseline_lm_4gram', '/embed')\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 1.8s. Train loss:  0.68704 Valid accuracy:    56.91\n",
      "Update parameters\n",
      "Epoch   1 took 1.8s. Train loss:  0.67480 Valid accuracy:    58.25\n",
      "Update parameters\n",
      "Epoch   2 took 1.7s. Train loss:  0.66387 Valid accuracy:    59.11\n",
      "Update parameters\n",
      "Epoch   3 took 2.0s. Train loss:  0.64975 Valid accuracy:    59.67\n",
      "Update parameters\n",
      "Epoch   4 took 2.5s. Train loss:  0.63449 Valid accuracy:    60.07\n",
      "Update parameters\n",
      "Epoch   5 took 2.1s. Train loss:  0.61806 Valid accuracy:    60.72\n",
      "Update parameters\n",
      "Epoch   6 took 2.1s. Train loss:  0.60632 Valid accuracy:    60.68\n",
      "Epoch   7 took 2.2s. Train loss:  0.59015 Valid accuracy:    60.53\n",
      "Epoch   8 took 2.3s. Train loss:  0.58294 Valid accuracy:    60.75\n",
      "Update parameters\n",
      "Epoch   9 took 2.1s. Train loss:  0.56880 Valid accuracy:    60.72\n",
      "Epoch  10 took 2.4s. Train loss:  0.56126 Valid accuracy:    60.94\n",
      "Update parameters\n",
      "Epoch  11 took 2.2s. Train loss:  0.55378 Valid accuracy:    60.64\n",
      "Epoch  12 took 2.1s. Train loss:  0.54669 Valid accuracy:    60.79\n",
      "Epoch  13 took 2.2s. Train loss:  0.53382 Valid accuracy:    60.79\n",
      "Epoch  14 took 1.9s. Train loss:  0.52633 Valid accuracy:    61.10\n",
      "Update parameters\n",
      "Epoch  15 took 2.0s. Train loss:  0.51361 Valid accuracy:    60.77\n",
      "Epoch  16 took 2.2s. Train loss:  0.50521 Valid accuracy:    60.74\n",
      "Epoch  17 took 2.2s. Train loss:  0.50291 Valid accuracy:    60.87\n",
      "Epoch  18 took 2.3s. Train loss:  0.49408 Valid accuracy:    60.54\n",
      "Epoch  19 took 2.3s. Train loss:  0.48522 Valid accuracy:    60.61\n",
      "Running model on test set. Test accuracy:    59.86\n"
     ]
    }
   ],
   "source": [
    "# Task 7 4-gram embedding with unlabeled data (This result is also good)\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "    clf.embed.populate('embeds_baseline_lm_4gram_unlabeled', '/embed')\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 took 2.3s. Train loss:  0.69129 Valid accuracy:    56.78\n",
      "Update parameters\n",
      "Epoch   1 took 2.1s. Train loss:  0.66809 Valid accuracy:    58.61\n",
      "Update parameters\n",
      "Epoch   2 took 2.3s. Train loss:  0.64600 Valid accuracy:    59.61\n",
      "Update parameters\n",
      "Epoch   3 took 2.2s. Train loss:  0.62200 Valid accuracy:    60.09\n",
      "Update parameters\n",
      "Epoch   4 took 2.4s. Train loss:  0.60083 Valid accuracy:    60.38\n",
      "Update parameters\n",
      "Epoch   5 took 2.2s. Train loss:  0.58465 Valid accuracy:    60.39\n",
      "Update parameters\n",
      "Epoch   6 took 2.1s. Train loss:  0.56873 Valid accuracy:    60.36\n",
      "Epoch   7 took 2.3s. Train loss:  0.55274 Valid accuracy:    60.10\n",
      "Epoch   8 took 2.0s. Train loss:  0.54387 Valid accuracy:    60.57\n",
      "Update parameters\n",
      "Epoch   9 took 2.1s. Train loss:  0.53253 Valid accuracy:    60.59\n",
      "Update parameters\n",
      "Epoch  10 took 2.3s. Train loss:  0.51981 Valid accuracy:    60.45\n",
      "Epoch  11 took 2.2s. Train loss:  0.50746 Valid accuracy:    60.22\n",
      "Epoch  12 took 2.0s. Train loss:  0.49908 Valid accuracy:    60.33\n",
      "Epoch  13 took 2.2s. Train loss:  0.49432 Valid accuracy:    60.14\n",
      "Epoch  14 took 2.2s. Train loss:  0.49186 Valid accuracy:    60.40\n",
      "Epoch  15 took 1.8s. Train loss:  0.48756 Valid accuracy:    60.23\n",
      "Epoch  16 took 2.2s. Train loss:  0.47320 Valid accuracy:    59.97\n",
      "Epoch  17 took 2.3s. Train loss:  0.47220 Valid accuracy:    60.13\n",
      "Epoch  18 took 2.1s. Train loss:  0.46528 Valid accuracy:    60.29\n",
      "Epoch  19 took 2.3s. Train loss:  0.45970 Valid accuracy:    60.23\n",
      "Running model on test set. Test accuracy:    59.25\n"
     ]
    }
   ],
   "source": [
    "# Task 7 without preinitialized embeddings\n",
    "\"\"\"Simple deep averaging net classifier\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from time import clock\n",
    "\n",
    "import dynet_config\n",
    "dynet_config.set(random_seed=42, autobatch=1)\n",
    "\n",
    "import dynet as dy\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 32\n",
    "VOCAB_SIZE = len(vocab)#__FIXME__\n",
    "\n",
    "\n",
    "def make_batches(data, batch_size):\n",
    "    batches = []\n",
    "    batch = []\n",
    "    for pair in data:\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "        batch.append(pair)\n",
    "\n",
    "    if batch:\n",
    "        batches.append(batch)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "class DANClassifier(object):\n",
    "    def __init__(self, params, vocab_size, hidden_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed = params.add_lookup_parameters((vocab_size, hidden_dim))\n",
    "        \n",
    "        self.W_hid = params.add_parameters((hidden_dim, hidden_dim))\n",
    "        self.b_hid = params.add_parameters((hidden_dim))\n",
    "\n",
    "        self.w_clf = params.add_parameters((1, hidden_dim))\n",
    "        self.b_clf = params.add_parameters((1))\n",
    "        \n",
    "        # Parameters used for test set\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "\n",
    "\n",
    "    def _predict(self, batch, train=True):\n",
    "\n",
    "        # load the network parameters\n",
    "        W_hid = dy.parameter(self.W_hid)\n",
    "        b_hid = dy.parameter(self.b_hid)\n",
    "        w_clf = dy.parameter(self.w_clf)\n",
    "        b_clf = dy.parameter(self.b_clf)\n",
    "\n",
    "        probas = []\n",
    "        # predict the probability of positive sentiment for each sentence\n",
    "        for _, sent in batch:\n",
    "            sent_embed = [dy.lookup(self.embed, w) for w in sent]\n",
    "            # Task 3\n",
    "            if train == True:\n",
    "                for i in range(len(sent_embed)):\n",
    "                    sent_embed[i] = dy.dropout(sent_embed[i], 0.5)\n",
    "\n",
    "            sent_embed = dy.average(sent_embed)\n",
    "\n",
    "            # hid = tanh(b + W * sent_embed)\n",
    "            # but it's faster to use affine_transform in dynet\n",
    "            hid = dy.affine_transform([b_hid, W_hid, sent_embed])\n",
    "            hid = dy.tanh(hid)\n",
    "\n",
    "            y_score = dy.affine_transform([b_clf, w_clf, hid])\n",
    "            y_proba = dy.logistic(y_score)\n",
    "            probas.append(y_proba)\n",
    "\n",
    "        return probas\n",
    "    \n",
    "    def update_best_parameters(self):\n",
    "        self.best_W_hid = self.W_hid\n",
    "        self.best_b_hid = self.b_hid\n",
    "\n",
    "        self.best_w_clf = self.w_clf\n",
    "        self.best_b_clf = self.b_clf\n",
    "        \n",
    "    def set_best_parameters(self):\n",
    "        self.W_hid = self.best_W_hid\n",
    "        self.b_hid = self.best_b_hid \n",
    "\n",
    "        self.w_clf = self.best_w_clf\n",
    "        self.b_clf = self.best_b_clf\n",
    "        \n",
    "    def batch_loss(self, sents, train=True):\n",
    "        probas = self._predict(sents, train)\n",
    "\n",
    "        # we pack all predicted probas into one vector of length batch_size\n",
    "        probas = dy.concatenate(probas)\n",
    "\n",
    "        # we make a dynet vector out of the true ys\n",
    "        y_true = dy.inputVector([y for y, _ in sents])\n",
    "\n",
    "        # classification loss: we use the logistic loss\n",
    "        # this function automatically sums over all entries.\n",
    "        total_loss = dy.binary_log_loss(probas, y_true)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def num_correct(self, sents):\n",
    "        probas = self._predict(sents, train=False)\n",
    "        probas = [p.value() for p in probas]\n",
    "        y_true = [y for y, _ in sents]\n",
    "\n",
    "        correct = 0\n",
    "        # FIXME: count the number of correct predictions here\n",
    "        # Task 2\n",
    "        y_pred = []\n",
    "        for p in probas:\n",
    "            if p > 0.5:\n",
    "                y_pred.append(True)\n",
    "            else:\n",
    "                y_pred.append(False)\n",
    "\n",
    "        correct = sum([1 for i in range(len(y_pred)) if y_pred[i] == y_true[i]])\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with open(os.path.join('processed', 'train_ix.pkl'), 'rb') as f:\n",
    "        train_ix = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join('processed', 'valid_ix.pkl'), 'rb') as f:\n",
    "        valid_ix = pickle.load(f)\n",
    "\n",
    "    # initialize dynet parameters and learning algorithm\n",
    "    params = dy.ParameterCollection()\n",
    "    trainer = dy.AdadeltaTrainer(params)\n",
    "    clf = DANClassifier(params, vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "    train_batches = make_batches(train_ix, BATCH_SIZE)\n",
    "    valid_batches = make_batches(valid_ix, BATCH_SIZE)\n",
    "    \n",
    "    best_valid_acc = 0\n",
    "    for it in range(MAX_EPOCHS):\n",
    "        tic = clock()\n",
    "\n",
    "        # iterate over all training batches, accumulate loss.\n",
    "        total_loss = 0\n",
    "        for batch in train_batches:\n",
    "            dy.renew_cg()\n",
    "            loss = clf.batch_loss(batch, train=True)\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            total_loss += loss.value()\n",
    "\n",
    "        # iterate over all validation batches, accumulate # correct pred.\n",
    "        valid_acc = 0\n",
    "        for batch in valid_batches:\n",
    "            dy.renew_cg()\n",
    "            valid_acc += clf.num_correct(batch)\n",
    "\n",
    "        valid_acc /= len(valid_ix)\n",
    "\n",
    "        toc = clock()\n",
    "\n",
    "        print((\"Epoch {:3d} took {:3.1f}s. \"\n",
    "               \"Train loss: {:8.5f} \"\n",
    "               \"Valid accuracy: {:8.2f}\").format(\n",
    "            it,\n",
    "            toc - tic,\n",
    "            total_loss / len(train_ix),\n",
    "            valid_acc * 100\n",
    "            ))\n",
    "        \n",
    "        if valid_acc * 100 > best_valid_acc:\n",
    "            best_valid_acc = valid_acc * 100\n",
    "            print('Update parameters')\n",
    "            clf.update_best_parameters()\n",
    "    \n",
    "    with open(os.path.join('processed', 'test_ix.pkl'), 'rb') as f:\n",
    "        test_ix = pickle.load(f)\n",
    "    \n",
    "    test_batches = make_batches(test_ix, BATCH_SIZE)\n",
    "    # iterate over all test batches, accumulate # correct pred.\n",
    "    test_acc = 0\n",
    "    clf.set_best_parameters()\n",
    "    \n",
    "    for batch in test_batches:\n",
    "        dy.renew_cg()\n",
    "        test_acc += clf.num_correct(batch)\n",
    "\n",
    "    test_acc /= len(test_ix)\n",
    "    print((\"Running model on test set. Test accuracy: {:8.2f}\").format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
